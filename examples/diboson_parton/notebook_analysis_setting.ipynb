{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MadMiner Parton-Level Analysis for $W\\gamma$: Step 2 - Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Johann Brehmer, Felix Kling, Kyle Cranmer 2018\n",
    "\n",
    "In this tutorial we'll demonstrate how to use MadMiner to generate train and test samples for the Information Geometry methods introduced in the following papers:\n",
    "- J. Brehmer, K. Cranmer, F. Kling, T. Plehn: [\"Better Higgs Measurements Through Information Geometry\"](https://arxiv.org/abs/1612.05261)\n",
    "- J. Brehmer, F. Kling, T. Plehn, T.M.P. Tait: [\"Better Higgs-CP Tests Through Information Geometry\"](https://arxiv.org/abs/1712.02350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "madminer_src_path = \"/Users/felixkling/Documents/GitHub/madminer\"\n",
    "sys.path.append(madminer_src_path)\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "% matplotlib inline\n",
    "\n",
    "from madminer.fisherinformation import FisherInformation\n",
    "from madminer.fisherinformation import project_information,profile_information\n",
    "\n",
    "from madminer.plotting import plot_fisher_information_contours_2d\n",
    "from madminer.plotting import plot_fisherinfo_barplot\n",
    "from madminer.plotting import kinematic_distribution_of_information\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import constant_benchmark_theta, multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input File sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Event Number\n",
    "usenumber='100k'\n",
    "nsamples=50000\n",
    "\n",
    "#NN Settings\n",
    "usename='100k_test'\n",
    "test_split=0.5\n",
    "\n",
    "#[label,n_hidden,n_epochs,initial_lr,final_lr,grad_x_regularization]\n",
    "listsettings=[\n",
    "     ['A1',(100,100),50,0.01,0.01,None],\n",
    "     ['A2',(100,100),50,0.01,0.001,None],\n",
    "     ['A3',(100,100),50,0.01,0.0001,None],\n",
    "     ['B1',(100,100),50,0.001,0.001,None],\n",
    "     ['B2',(100,100),50,0.001,0.0001,None],\n",
    "     ['B3',(100,100),50,0.001,0.00001,None],\n",
    "]\n",
    "listsettings=[\n",
    "     ['A',(100,100),50,0.1,0.0001,None],\n",
    "     ['B',(100,100),50,0.01,0.0001,None],\n",
    "     ['C',(100,100),50,0.001,0.0001,None],\n",
    "     ['D',(100,100),50,0.0001,0.0001,None],\n",
    "]\n",
    "listsettings=[\n",
    "     ['2',(100,100),50,0.001,0.0001,None],\n",
    "     ['3',(100,100,100),50,0.001,0.0001,None],\n",
    "     ['4',(100,100,100,100),50,0.001,0.0001,None],\n",
    "     ['5',(100,100,100,100,100),50,0.001,0.0001,None]\n",
    "]\n",
    "listsettings=[\n",
    "     ['None',(100,100),50,0.001,0.0001,None],\n",
    "     ['1',(100,100),50,0.001,0.0001,1],\n",
    "     ['0.1',(100,100),50,0.001,0.0001,0.1],\n",
    "     ['0.01',(100,100),50,0.001,0.0001,0.01],\n",
    "     ['0.001',(100,100),50,0.001,0.0001,0.001]\n",
    "]\n",
    "\n",
    "listsettings=[\n",
    "     ['2',(100,100),50,0.001,0.0001,None],\n",
    "     ['5',(100,100),50,0.001,0.0001,None],\n",
    "     ['10',(100,100),50,0.001,0.0001,None],\n",
    "     ['20',(100,100),50,0.001,0.0001,None],\n",
    "     ['50',(100,100),50,0.001,0.0001,None],\n",
    "     ['100',(100,100),50,0.001,0.0001,None],\n",
    "     ['200',(100,100),50,0.001,0.0001,None],\n",
    "     ['500',(100,100),50,0.001,0.0001,None]\n",
    "]\n",
    "\n",
    "\n",
    "#file names and directories\n",
    "useinputdata = 'data/madminer_wgamma_observables_'+usenumber+'.h5'\n",
    "usesamplesdir = 'data/samples_'+usename+'/'\n",
    "usemodelsdir = 'models/samples_'+usename+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make (unweighted) training and test samples with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:25  \n",
      "22:25  ------------------------------------------------------------\n",
      "22:25  |                                                          |\n",
      "22:25  |  MadMiner v2018.11.02                                    |\n",
      "22:25  |                                                          |\n",
      "22:25  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "22:25  |                                                          |\n",
      "22:25  ------------------------------------------------------------\n",
      "22:25  \n",
      "22:25  Loading data from data/madminer_wgamma_observables_100k.h5\n",
      "22:25  Found 2 parameters:\n",
      "22:25     CWL2 (LHA: dim6 2, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:25     CPWL2 (LHA: dim6 5, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:25  Found 6 benchmarks:\n",
      "22:25     sm: CWL2 = 0.00e+00, CPWL2 = 0.00e+00\n",
      "22:25     w: CWL2 = 20.00, CPWL2 = 0.00e+00\n",
      "22:25     morphing_basis_vector_2: CWL2 = -4.72e+01, CPWL2 = 23.25\n",
      "22:25     morphing_basis_vector_3: CWL2 = 18.64, CPWL2 = 32.06\n",
      "22:25     morphing_basis_vector_4: CWL2 = 11.41, CPWL2 = -3.26e+01\n",
      "22:25     morphing_basis_vector_5: CWL2 = -4.05e+01, CPWL2 = -3.67e+01\n",
      "22:25  Found 23 observables: px_l, px_v, px_a, py_l, py_v, py_a, pz_l, pz_v, pz_a, e_l, e_v, e_a, pt_l, pt_v, pt_a, eta_l, eta_v, eta_a, dphi_lv, dphi_la, dphi_va, m_lv, m_lva\n",
      "22:25  Found 100000 events\n",
      "22:25  Found morphing setup with 6 components\n",
      "22:25  Extracting training sample for local score regression. Sampling and score evaluation according to (u'benchmark', u'sm')\n",
      "22:25  Effective number of samples: 49999.99999996653\n",
      "22:25  Extracting training sample for local score regression. Sampling and score evaluation according to (u'benchmark', u'sm')\n",
      "22:25  Effective number of samples: 49999.99999996653\n",
      "22:25  Extracting evaluation sample. Sampling according to (u'benchmark', u'sm')\n",
      "22:25  Effective number of samples: 49998.99999996653\n"
     ]
    }
   ],
   "source": [
    "#create sample augmenter\n",
    "sa = SampleAugmenter(useinputdata, debug=False)\n",
    "n_estimators = 2\n",
    "\n",
    "#augment train sample\n",
    "for i in range(n_estimators):\n",
    "    x, theta, t_xz = sa.extract_samples_train_local(\n",
    "        theta=constant_benchmark_theta('sm'),\n",
    "        n_samples=nsamples,\n",
    "        folder='./'+usesamplesdir,\n",
    "        filename='train{}'.format(i),\n",
    "        test_split=test_split\n",
    "    )\n",
    "    if i==0:\n",
    "        tx_truth=t_xz\n",
    "\n",
    "#augment test sample\n",
    "x, theta = sa.extract_samples_test(\n",
    "    theta=constant_benchmark_theta('sm'),\n",
    "    n_samples=nsamples,\n",
    "    folder='./'+usesamplesdir,\n",
    "    filename='test',\n",
    "    test_split=test_split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a neural network to estimate the score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a) Change Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:25  Training 2 estimators in ensemble\n",
      "22:25  Training estimator 1 / 2 in ensemble\n",
      "22:25  Starting training\n",
      "22:25    Method:                 sally\n",
      "22:25    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:25                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:25    Features:               all\n",
      "22:25    Method:                 sally\n",
      "22:25    Hidden layers:          (100, 100)\n",
      "22:25    Activation function:    tanh\n",
      "22:25    Batch size:             128\n",
      "22:25    Trainer:                amsgrad\n",
      "22:25    Epochs:                 50\n",
      "22:25    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:25    Validation split:       None\n",
      "22:25    Early stopping:         True\n",
      "22:25    Scale inputs:           True\n",
      "22:25    Regularization:         None\n",
      "22:25  Loading training data\n",
      "22:25  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:25  Rescaling inputs\n",
      "22:25  Creating model for method sally\n",
      "22:25  Training model\n",
      "22:25    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:25    Epoch 10: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:25    Epoch 15: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:25    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:26    Epoch 25: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:26    Epoch 30: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:26    Epoch 35: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:26    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:26    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:26    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:26  Finished training\n",
      "22:26  Training estimator 2 / 2 in ensemble\n",
      "22:26  Starting training\n",
      "22:26    Method:                 sally\n",
      "22:26    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:26                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:26    Features:               all\n",
      "22:26    Method:                 sally\n",
      "22:26    Hidden layers:          (100, 100)\n",
      "22:26    Activation function:    tanh\n",
      "22:26    Batch size:             128\n",
      "22:26    Trainer:                amsgrad\n",
      "22:26    Epochs:                 50\n",
      "22:26    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:26    Validation split:       None\n",
      "22:26    Early stopping:         True\n",
      "22:26    Scale inputs:           True\n",
      "22:26    Regularization:         None\n",
      "22:26  Loading training data\n",
      "22:26  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:26  Rescaling inputs\n",
      "22:26  Creating model for method sally\n",
      "22:26  Training model\n",
      "22:26    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:26    Epoch 10: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:26    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:26    Epoch 20: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:26    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:26    Epoch 30: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:26    Epoch 35: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:27    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:27    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:27    Epoch 50: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:27  Finished training\n",
      "22:27  Training 2 estimators in ensemble\n",
      "22:27  Training estimator 1 / 2 in ensemble\n",
      "22:27  Starting training\n",
      "22:27    Method:                 sally\n",
      "22:27    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:27                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:27    Features:               all\n",
      "22:27    Method:                 sally\n",
      "22:27    Hidden layers:          (100, 100)\n",
      "22:27    Activation function:    tanh\n",
      "22:27    Batch size:             128\n",
      "22:27    Trainer:                amsgrad\n",
      "22:27    Epochs:                 50\n",
      "22:27    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:27    Validation split:       None\n",
      "22:27    Early stopping:         True\n",
      "22:27    Scale inputs:           True\n",
      "22:27    Regularization:         None\n",
      "22:27  Loading training data\n",
      "22:27  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:27  Rescaling inputs\n",
      "22:27  Creating model for method sally\n",
      "22:27  Training model\n",
      "22:27    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:27    Epoch 10: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:27    Epoch 15: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:27    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:27    Epoch 25: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:27    Epoch 30: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:27    Epoch 35: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:27    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:27    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:27    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:27  Finished training\n",
      "22:27  Training estimator 2 / 2 in ensemble\n",
      "22:27  Starting training\n",
      "22:27    Method:                 sally\n",
      "22:27    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:27                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:27    Features:               all\n",
      "22:27    Method:                 sally\n",
      "22:27    Hidden layers:          (100, 100)\n",
      "22:27    Activation function:    tanh\n",
      "22:27    Batch size:             128\n",
      "22:27    Trainer:                amsgrad\n",
      "22:27    Epochs:                 50\n",
      "22:27    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:27    Validation split:       None\n",
      "22:27    Early stopping:         True\n",
      "22:27    Scale inputs:           True\n",
      "22:27    Regularization:         None\n",
      "22:27  Loading training data\n",
      "22:27  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:27  Rescaling inputs\n",
      "22:27  Creating model for method sally\n",
      "22:27  Training model\n",
      "22:28    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:28    Epoch 10: train loss 0.0023 (mse_score: 0.0023)\n",
      "22:28    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:28    Epoch 20: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:28    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:28    Epoch 30: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:28    Epoch 35: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:28    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:28    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:28    Epoch 50: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:28  Finished training\n",
      "22:28  Training 2 estimators in ensemble\n",
      "22:28  Training estimator 1 / 2 in ensemble\n",
      "22:28  Starting training\n",
      "22:28    Method:                 sally\n",
      "22:28    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:28                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:28    Features:               all\n",
      "22:28    Method:                 sally\n",
      "22:28    Hidden layers:          (100, 100)\n",
      "22:28    Activation function:    tanh\n",
      "22:28    Batch size:             128\n",
      "22:28    Trainer:                amsgrad\n",
      "22:28    Epochs:                 50\n",
      "22:28    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:28    Validation split:       None\n",
      "22:28    Early stopping:         True\n",
      "22:28    Scale inputs:           True\n",
      "22:28    Regularization:         None\n",
      "22:28  Loading training data\n",
      "22:28  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:28  Rescaling inputs\n",
      "22:28  Creating model for method sally\n",
      "22:28  Training model\n",
      "22:28    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:28    Epoch 10: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:28    Epoch 15: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:29    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:29    Epoch 25: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:29    Epoch 30: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:29    Epoch 35: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:29    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:29    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:29    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:29  Finished training\n",
      "22:29  Training estimator 2 / 2 in ensemble\n",
      "22:29  Starting training\n",
      "22:29    Method:                 sally\n",
      "22:29    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:29                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:29    Features:               all\n",
      "22:29    Method:                 sally\n",
      "22:29    Hidden layers:          (100, 100)\n",
      "22:29    Activation function:    tanh\n",
      "22:29    Batch size:             128\n",
      "22:29    Trainer:                amsgrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:29    Epochs:                 50\n",
      "22:29    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:29    Validation split:       None\n",
      "22:29    Early stopping:         True\n",
      "22:29    Scale inputs:           True\n",
      "22:29    Regularization:         None\n",
      "22:29  Loading training data\n",
      "22:29  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:29  Rescaling inputs\n",
      "22:29  Creating model for method sally\n",
      "22:29  Training model\n",
      "22:29    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:29    Epoch 10: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:29    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:29    Epoch 20: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:29    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:29    Epoch 30: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:29    Epoch 35: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:30    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:30    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:30    Epoch 50: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:30  Finished training\n",
      "22:30  Training 2 estimators in ensemble\n",
      "22:30  Training estimator 1 / 2 in ensemble\n",
      "22:30  Starting training\n",
      "22:30    Method:                 sally\n",
      "22:30    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:30                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:30    Features:               all\n",
      "22:30    Method:                 sally\n",
      "22:30    Hidden layers:          (100, 100)\n",
      "22:30    Activation function:    tanh\n",
      "22:30    Batch size:             128\n",
      "22:30    Trainer:                amsgrad\n",
      "22:30    Epochs:                 50\n",
      "22:30    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:30    Validation split:       None\n",
      "22:30    Early stopping:         True\n",
      "22:30    Scale inputs:           True\n",
      "22:30    Regularization:         None\n",
      "22:30  Loading training data\n",
      "22:30  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:30  Rescaling inputs\n",
      "22:30  Creating model for method sally\n",
      "22:30  Training model\n",
      "22:30    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:30    Epoch 10: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:30    Epoch 15: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:30    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:30    Epoch 25: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:30    Epoch 30: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:30    Epoch 35: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:30    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:30    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:30    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:30  Finished training\n",
      "22:30  Training estimator 2 / 2 in ensemble\n",
      "22:30  Starting training\n",
      "22:30    Method:                 sally\n",
      "22:30    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:30                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:30    Features:               all\n",
      "22:30    Method:                 sally\n",
      "22:30    Hidden layers:          (100, 100)\n",
      "22:30    Activation function:    tanh\n",
      "22:30    Batch size:             128\n",
      "22:30    Trainer:                amsgrad\n",
      "22:30    Epochs:                 50\n",
      "22:30    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:30    Validation split:       None\n",
      "22:30    Early stopping:         True\n",
      "22:30    Scale inputs:           True\n",
      "22:30    Regularization:         None\n",
      "22:30  Loading training data\n",
      "22:30  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:30  Rescaling inputs\n",
      "22:30  Creating model for method sally\n",
      "22:30  Training model\n",
      "22:31    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:31    Epoch 10: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:31    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:31    Epoch 20: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:31    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:31    Epoch 30: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:31    Epoch 35: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:31    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:31    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:31    Epoch 50: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:31  Finished training\n",
      "22:31  Training 2 estimators in ensemble\n",
      "22:31  Training estimator 1 / 2 in ensemble\n",
      "22:31  Starting training\n",
      "22:31    Method:                 sally\n",
      "22:31    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:31                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:31    Features:               all\n",
      "22:31    Method:                 sally\n",
      "22:31    Hidden layers:          (100, 100)\n",
      "22:31    Activation function:    tanh\n",
      "22:31    Batch size:             128\n",
      "22:31    Trainer:                amsgrad\n",
      "22:31    Epochs:                 50\n",
      "22:31    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:31    Validation split:       None\n",
      "22:31    Early stopping:         True\n",
      "22:31    Scale inputs:           True\n",
      "22:31    Regularization:         None\n",
      "22:31  Loading training data\n",
      "22:31  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:31  Rescaling inputs\n",
      "22:31  Creating model for method sally\n",
      "22:31  Training model\n",
      "22:31    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:31    Epoch 10: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:31    Epoch 15: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:31    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:32    Epoch 25: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:32    Epoch 30: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:32    Epoch 35: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:32    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:32    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:32    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:32  Finished training\n",
      "22:32  Training estimator 2 / 2 in ensemble\n",
      "22:32  Starting training\n",
      "22:32    Method:                 sally\n",
      "22:32    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:32                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:32    Features:               all\n",
      "22:32    Method:                 sally\n",
      "22:32    Hidden layers:          (100, 100)\n",
      "22:32    Activation function:    tanh\n",
      "22:32    Batch size:             128\n",
      "22:32    Trainer:                amsgrad\n",
      "22:32    Epochs:                 50\n",
      "22:32    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:32    Validation split:       None\n",
      "22:32    Early stopping:         True\n",
      "22:32    Scale inputs:           True\n",
      "22:32    Regularization:         None\n",
      "22:32  Loading training data\n",
      "22:32  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:32  Rescaling inputs\n",
      "22:32  Creating model for method sally\n",
      "22:32  Training model\n",
      "22:32    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:32    Epoch 10: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:32    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:32    Epoch 20: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:32    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:32    Epoch 30: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:32    Epoch 35: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:33    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:33    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:33    Epoch 50: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:33  Finished training\n",
      "22:33  Training 2 estimators in ensemble\n",
      "22:33  Training estimator 1 / 2 in ensemble\n",
      "22:33  Starting training\n",
      "22:33    Method:                 sally\n",
      "22:33    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:33                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:33    Features:               all\n",
      "22:33    Method:                 sally\n",
      "22:33    Hidden layers:          (100, 100)\n",
      "22:33    Activation function:    tanh\n",
      "22:33    Batch size:             128\n",
      "22:33    Trainer:                amsgrad\n",
      "22:33    Epochs:                 50\n",
      "22:33    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:33    Validation split:       None\n",
      "22:33    Early stopping:         True\n",
      "22:33    Scale inputs:           True\n",
      "22:33    Regularization:         None\n",
      "22:33  Loading training data\n",
      "22:33  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:33  Rescaling inputs\n",
      "22:33  Creating model for method sally\n",
      "22:33  Training model\n",
      "22:33    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:33    Epoch 10: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:33    Epoch 15: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:33    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:33    Epoch 25: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:33    Epoch 30: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:33    Epoch 35: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:33    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:33    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:34    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:34  Finished training\n",
      "22:34  Training estimator 2 / 2 in ensemble\n",
      "22:34  Starting training\n",
      "22:34    Method:                 sally\n",
      "22:34    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:34                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:34    Features:               all\n",
      "22:34    Method:                 sally\n",
      "22:34    Hidden layers:          (100, 100)\n",
      "22:34    Activation function:    tanh\n",
      "22:34    Batch size:             128\n",
      "22:34    Trainer:                amsgrad\n",
      "22:34    Epochs:                 50\n",
      "22:34    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:34    Validation split:       None\n",
      "22:34    Early stopping:         True\n",
      "22:34    Scale inputs:           True\n",
      "22:34    Regularization:         None\n",
      "22:34  Loading training data\n",
      "22:34  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:34  Rescaling inputs\n",
      "22:34  Creating model for method sally\n",
      "22:34  Training model\n",
      "22:34    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:34    Epoch 10: train loss 0.0023 (mse_score: 0.0023)\n",
      "22:34    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:34    Epoch 20: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:34    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:34    Epoch 30: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:34    Epoch 35: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:34    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:34    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:35    Epoch 50: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:35  Finished training\n",
      "22:35  Training 2 estimators in ensemble\n",
      "22:35  Training estimator 1 / 2 in ensemble\n",
      "22:35  Starting training\n",
      "22:35    Method:                 sally\n",
      "22:35    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:35                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:35    Features:               all\n",
      "22:35    Method:                 sally\n",
      "22:35    Hidden layers:          (100, 100)\n",
      "22:35    Activation function:    tanh\n",
      "22:35    Batch size:             128\n",
      "22:35    Trainer:                amsgrad\n",
      "22:35    Epochs:                 50\n",
      "22:35    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:35    Validation split:       None\n",
      "22:35    Early stopping:         True\n",
      "22:35    Scale inputs:           True\n",
      "22:35    Regularization:         None\n",
      "22:35  Loading training data\n",
      "22:35  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:35  Rescaling inputs\n",
      "22:35  Creating model for method sally\n",
      "22:35  Training model\n",
      "22:35    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:35    Epoch 10: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:35    Epoch 15: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:35    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:35    Epoch 25: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:35    Epoch 30: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:35    Epoch 35: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:35    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:35    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:35    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:35  Finished training\n",
      "22:35  Training estimator 2 / 2 in ensemble\n",
      "22:35  Starting training\n",
      "22:35    Method:                 sally\n",
      "22:35    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:35                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:35    Features:               all\n",
      "22:35    Method:                 sally\n",
      "22:35    Hidden layers:          (100, 100)\n",
      "22:35    Activation function:    tanh\n",
      "22:35    Batch size:             128\n",
      "22:35    Trainer:                amsgrad\n",
      "22:35    Epochs:                 50\n",
      "22:35    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:35    Validation split:       None\n",
      "22:35    Early stopping:         True\n",
      "22:35    Scale inputs:           True\n",
      "22:35    Regularization:         None\n",
      "22:35  Loading training data\n",
      "22:35  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:35  Rescaling inputs\n",
      "22:35  Creating model for method sally\n",
      "22:35  Training model\n",
      "22:35    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:35    Epoch 10: train loss 0.0023 (mse_score: 0.0023)\n",
      "22:35    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:36    Epoch 20: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:36    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:36    Epoch 30: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:36    Epoch 35: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:36    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:36    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:36    Epoch 50: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:36  Finished training\n",
      "22:36  Training 2 estimators in ensemble\n",
      "22:36  Training estimator 1 / 2 in ensemble\n",
      "22:36  Starting training\n",
      "22:36    Method:                 sally\n",
      "22:36    Training data: x at data/samples_100k_test/x_train0.npy\n",
      "22:36                   t_xz (theta0) at  data/samples_100k_test/t_xz_train0.npy\n",
      "22:36    Features:               all\n",
      "22:36    Method:                 sally\n",
      "22:36    Hidden layers:          (100, 100)\n",
      "22:36    Activation function:    tanh\n",
      "22:36    Batch size:             128\n",
      "22:36    Trainer:                amsgrad\n",
      "22:36    Epochs:                 50\n",
      "22:36    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:36    Validation split:       None\n",
      "22:36    Early stopping:         True\n",
      "22:36    Scale inputs:           True\n",
      "22:36    Regularization:         None\n",
      "22:36  Loading training data\n",
      "22:36  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:36  Rescaling inputs\n",
      "22:36  Creating model for method sally\n",
      "22:36  Training model\n",
      "22:36    Epoch 5: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:36    Epoch 10: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:36    Epoch 15: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:36    Epoch 20: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:36    Epoch 25: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:36    Epoch 30: train loss 0.0019 (mse_score: 0.0019)\n",
      "22:37    Epoch 35: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:37    Epoch 40: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:37    Epoch 45: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:37    Epoch 50: train loss 0.0018 (mse_score: 0.0018)\n",
      "22:37  Finished training\n",
      "22:37  Training estimator 2 / 2 in ensemble\n",
      "22:37  Starting training\n",
      "22:37    Method:                 sally\n",
      "22:37    Training data: x at data/samples_100k_test/x_train1.npy\n",
      "22:37                   t_xz (theta0) at  data/samples_100k_test/t_xz_train1.npy\n",
      "22:37    Features:               all\n",
      "22:37    Method:                 sally\n",
      "22:37    Hidden layers:          (100, 100)\n",
      "22:37    Activation function:    tanh\n",
      "22:37    Batch size:             128\n",
      "22:37    Trainer:                amsgrad\n",
      "22:37    Epochs:                 50\n",
      "22:37    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:37    Validation split:       None\n",
      "22:37    Early stopping:         True\n",
      "22:37    Scale inputs:           True\n",
      "22:37    Regularization:         None\n",
      "22:37  Loading training data\n",
      "22:37  Found 50000 samples with 2 parameters and 23 observables\n",
      "22:37  Rescaling inputs\n",
      "22:37  Creating model for method sally\n",
      "22:37  Training model\n",
      "22:37    Epoch 5: train loss 0.0024 (mse_score: 0.0024)\n",
      "22:37    Epoch 10: train loss 0.0023 (mse_score: 0.0023)\n",
      "22:37    Epoch 15: train loss 0.0022 (mse_score: 0.0022)\n",
      "22:37    Epoch 20: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:37    Epoch 25: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:37    Epoch 30: train loss 0.0021 (mse_score: 0.0021)\n",
      "22:37    Epoch 35: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:37    Epoch 40: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:37    Epoch 45: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:37    Epoch 50: train loss 0.0020 (mse_score: 0.0020)\n",
      "22:37  Finished training\n"
     ]
    }
   ],
   "source": [
    "# Setup Lists\n",
    "list_ttest=[]\n",
    "\n",
    "#Run NN\n",
    "for ii in range(len(listsettings)):\n",
    "    thissetting=listsettings[ii]\n",
    "    \n",
    "    #Setup ensemble\n",
    "    ensemble = EnsembleForge(estimators=n_estimators)\n",
    "    #train ensemble\n",
    "    ensemble.train_all(\n",
    "        method='sally',\n",
    "        x_filename=[usesamplesdir+'x_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "        t_xz0_filename=[usesamplesdir+'t_xz_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "        validation_split=None,\n",
    "        n_hidden=thissetting[1],\n",
    "        n_epochs=thissetting[2],\n",
    "        initial_lr=thissetting[3],\n",
    "        final_lr=thissetting[4],\n",
    "        grad_x_regularization=thissetting[5]\n",
    "    )\n",
    "\n",
    "#    tx_train, _ = ensemble.evaluate(usesamplesdir+'x_train0.npy')\n",
    "#    list_ttest =  list_ttest + [tx_train]\n",
    "    \n",
    "    #save ensemble\n",
    "    ensemble.save(usemodelsdir+'sally_ensemble_{}'.format(thissetting[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. FisherInfo for Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:37  Loading data from data/madminer_wgamma_observables_100k.h5\n",
      "22:37  Found 2 parameters:\n",
      "22:37     CWL2 (LHA: dim6 2, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:37     CPWL2 (LHA: dim6 5, maximal power in squared ME: (2,), range: (-50.0, 50.0))\n",
      "22:37  Found 6 benchmarks:\n",
      "22:37     sm: CWL2 = 0.00e+00, CPWL2 = 0.00e+00\n",
      "22:37     w: CWL2 = 20.00, CPWL2 = 0.00e+00\n",
      "22:37     morphing_basis_vector_2: CWL2 = -4.72e+01, CPWL2 = 23.25\n",
      "22:37     morphing_basis_vector_3: CWL2 = 18.64, CPWL2 = 32.06\n",
      "22:37     morphing_basis_vector_4: CWL2 = 11.41, CPWL2 = -3.26e+01\n",
      "22:37     morphing_basis_vector_5: CWL2 = -4.05e+01, CPWL2 = -3.67e+01\n",
      "22:37  Found 23 observables: px_l, px_v, px_a, py_l, py_v, py_a, pz_l, pz_v, pz_a, e_l, e_v, e_a, pt_l, pt_v, pt_a, eta_l, eta_v, eta_a, dphi_lv, dphi_la, dphi_va, m_lv, m_lva\n",
      "22:37  Found 100000 events\n",
      "22:37  Found morphing setup with 6 components\n",
      "22:38  Found ensemble with 2 estimators and expectations None\n",
      "22:38  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:38  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [-0.0009251   0.00106851]\n",
      "22:38  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [0.00043497 0.0005626 ]\n",
      "22:38  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n",
      "22:38  Found ensemble with 2 estimators and expectations None\n",
      "22:38  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:38  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [-0.00041985  0.00129519]\n",
      "22:38  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [-0.00094678 -0.00173927]\n",
      "22:38  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n",
      "22:38  Found ensemble with 2 estimators and expectations None\n",
      "22:38  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:38  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [ 0.00061959 -0.00038605]\n",
      "22:38  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [-0.00066137  0.00066878]\n",
      "22:38  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n",
      "22:38  Found ensemble with 2 estimators and expectations None\n",
      "22:38  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:38  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [7.2007235e-05 2.0525223e-03]\n",
      "22:38  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:38  Expected score (should be close to zero): [-0.00094813  0.00111399]\n",
      "22:38  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n",
      "22:39  Found ensemble with 2 estimators and expectations None\n",
      "22:39  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:39  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [0.0005266  0.00094531]\n",
      "22:39  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [0.00094992 0.00196891]\n",
      "22:39  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n",
      "22:39  Found ensemble with 2 estimators and expectations None\n",
      "22:39  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:39  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [0.00088215 0.00120914]\n",
      "22:39  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [-0.0014434  -0.00106851]\n",
      "22:39  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n",
      "22:39  Found ensemble with 2 estimators and expectations None\n",
      "22:39  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:39  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [6.9222166e-05 3.2763950e-05]\n",
      "22:39  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [0.00025962 0.0017278 ]\n",
      "22:39  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n",
      "22:39  Found ensemble with 2 estimators and expectations None\n",
      "22:39  Evaluating Fisher information for 2 estimators in ensemble\n",
      "22:39  Starting evaluation for estimator 1 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [-9.973447e-05  1.409347e-03]\n",
      "22:39  Starting evaluation for estimator 2 / 2 in ensemble\n",
      "22:39  Expected score (should be close to zero): [ 0.00056307 -0.00162364]\n",
      "22:39  Uncertainty on Fisher information with single SALLY instance only reflects the covariance from the rate, not the kinematic part!\n"
     ]
    }
   ],
   "source": [
    "#Setup MadFisher\n",
    "fisher = FisherInformation(useinputdata, debug=False)\n",
    "\n",
    "# Setup Lists\n",
    "list_mean =[]\n",
    "list_error=[]\n",
    "list_color=[]\n",
    "list_style=[]\n",
    "list_label=[]\n",
    "\n",
    "#Run MadFisher\n",
    "for ii in range(len(listsettings)):\n",
    "    thissetting=listsettings[ii]\n",
    "    \n",
    "    fi_det_mean_all, fi_det_cov_all = fisher.calculate_fisher_information_full_detector(\n",
    "        theta=[0.,0.], luminosity=300*1000.,\n",
    "        model_file=usemodelsdir+'sally_ensemble_{}'.format(thissetting[0]),\n",
    "        unweighted_x_sample_file=usesamplesdir+'x_test.npy'\n",
    "    )\n",
    "    \n",
    "    list_mean  = list_mean  + [fi_det_mean_all]\n",
    "    list_error = list_error + [fi_det_cov_all*n_estimators]\n",
    "    list_color = list_color + ['C'+str(ii)]\n",
    "    list_style = list_style + [\"solid\"]\n",
    "    list_label = list_label + [thissetting[0]]\n",
    "\n",
    "#Run MadFisher Truth\n",
    "fi_pl_mean_full , fi_pl_error_full = fisher.calculate_fisher_information_full_truth(theta=[0.,0.],luminosity=300*1000.)\n",
    "list_mean  = list_mean  + [fi_pl_mean_full]\n",
    "list_error = list_error + [fi_pl_error_full]\n",
    "list_color = list_color + [\"black\"]\n",
    "list_style = list_style + [\"dashed\"]\n",
    "list_label = list_label + [\"truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109aea3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot FisherInfo\n",
    "fignn = plot_fisher_information_contours_2d(\n",
    "    list_mean,\n",
    "    list_error,\n",
    "    colors=list_color,\n",
    "    linestyles=list_style,\n",
    "    inline_labels=list_label,\n",
    "    xrange=(-7.,7.),\n",
    "    yrange=(-4.,4.),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ece822e37b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistsettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mthissetting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlistsettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmsq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_ttest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mthissetting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmsq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#mean squared error test \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for ii in range(len(listsettings)):\n",
    "    thissetting=listsettings[ii]\n",
    "    msq = mean_squared_error(list_ttest[ii],tx_truth)\n",
    "    print (thissetting[0],\": \",msq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
