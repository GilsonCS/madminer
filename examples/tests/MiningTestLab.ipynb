{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MadMiner : Laboritory for Testing - Room 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a research lab to test the validate of the mined material.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Reseach Library: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set right path to MadMiner\n",
    "import sys\n",
    "import os\n",
    "delphes_src_path = \"/Users/felixkling/Documents/GitHub/delphesminer\"\n",
    "sys.path.append(delphes_src_path)\n",
    "madminer_src_path = \"/Users/felixkling/Documents/GitHub/madminer\"\n",
    "sys.path.append(madminer_src_path)\n",
    "\n",
    "#Import MadMiner\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from madminer.goldmine import GoldMine\n",
    "from madminer.refinery import combine_and_shuffle\n",
    "from madminer.refinery import Refinery\n",
    "from madminer.refinery import constant_benchmark_theta, multiple_benchmark_thetas\n",
    "from madminer.refinery import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.tools.plots import plot_2d_morphing_basis\n",
    "from delphesprocessor.delphesprocessor import DelphesProcessor\n",
    "\n",
    "#Set Path to MG5 directory\n",
    "mg_dir = '/Users/felixkling/work/MG5_aMC_v2_6_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Select Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last important MadMiner class is the `Smithy`. From all the data we have in the HDF5 file now, it extracts unweighted samples including the augmented data (\"gold\") that is needed as training and evaluation data for the Machine Learning algorithms.\n",
    "\n",
    "The Refinery class defines four different high-level functions to generate train or test samples:\n",
    "\n",
    "    extract_samples_train_plain(), which only saves observations x, for instance for histograms or ABC;\n",
    "    extract_samples_train_local() for methods like SALLY and SALLINO;\n",
    "    extract_samples_train_ratio() for techniques like CARL, ROLR, CASCAL, and RASCAL; and\n",
    "    extract_samples_test() for the evaluation of any method.\n",
    "\n",
    "For the arguments theta, theta0, or theta1, you can use the helper functions constant_benchmark_theta(), multiple_benchmark_thetas(), constant_morphing_theta(), multiple_morphing_thetas(), and random_morphing_thetas(), all defined in the smithy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinery = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=True)\n",
    "\n",
    "A, theta = refinery.extract_samples_test(\n",
    "    theta=constant_morphing_theta(np.array([1.e-5,0.])),\n",
    "    n_samples=1000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A first look: Corner Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at a corner plot. They look cool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "labels = [r'$p_{T,e}$ [GeV]', r'$p_{T,\\mu}$ [GeV]', r'$\\Delta \\eta_{\\ell\\ell}$', r'$\\Delta \\phi_{\\ell\\ell}$']\n",
    "ranges = [(0., 500.), (0., 500.), (0.,3.), (0.,6.2)]\n",
    "\n",
    "_ = corner.corner(A, color='C0', labels=labels, range=ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quality Test A : Comapre Refinery to Raw Distribution for same Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of refinery.extract_samples_test(theta) has to have the same distribution as in the Delphes ROOT file, if theta is the same we used to generate the original MadGraph samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Parameter Point\n",
    "point = np.array([8.08,9.5]);\n",
    "\n",
    "#Setup Refinery and load data\n",
    "refinery = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=True)\n",
    "\n",
    "x, theta = refinery.extract_samples_test(\n",
    "    theta=constant_morphing_theta(point),\n",
    "    n_samples=100000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='test'\n",
    ")\n",
    "raw_x, raw_weights = refinery.extract_raw_data(theta=point)\n",
    "\n",
    "# Number of Observables and Total Weight\n",
    "n_observables = len(raw_x[0])\n",
    "weight_total  = sum(raw_weights)\n",
    "\n",
    "# Raw Data:\n",
    "n_events_raw  = len(raw_x)\n",
    "data_raw      = np.zeros( (n_observables,n_events_raw) )\n",
    "weight_raw    = np.zeros( (n_events_raw) )\n",
    "for i in range(0,n_observables):\n",
    "    for j in range(0,n_events_raw):\n",
    "        data_raw[i][j]   = raw_x[j][i]\n",
    "\n",
    "for j in range(0,n_events_raw):\n",
    "    weight_raw[j] = raw_weights[j]\n",
    "        \n",
    "# Refined Data\n",
    "n_events_refine  = len(x)\n",
    "data_refine      = np.zeros( (n_observables,n_events_refine) )\n",
    "weight_refine    = np.zeros( (n_events_refine) )\n",
    "for i in range(0,n_observables):\n",
    "    for j in range(0,n_events_refine):\n",
    "        data_refine[i][j] = x[j][i]\n",
    "\n",
    "for j in range(0,n_events_refine):\n",
    "    weight_refine[j] = weight_total/n_events_refine   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some plotting\n",
    "xlabels = [r'$p_{T,e}$ [GeV]', r'$p_{T,\\mu}$ [GeV]', r'$\\Delta \\eta_{\\ell\\ell}$', r'$\\Delta \\phi_{\\ell\\ell}$']\n",
    "ylabels = [r'$d\\sigma/dp_{T,e}$ [pb/bin]', r'$d\\sigma/p_{T,\\mu}$ [pb/bin]', r'$d\\sigma/\\Delta \\eta_{\\ell\\ell} [pb/bin]$', r'$d\\sigma/\\Delta \\phi_{\\ell\\ell} [pb/bin]$']\n",
    "ranges = [(0., 500.), (0., 500.), (0.,3.), (0.,6.2)]\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "f.set_size_inches(11,8)\n",
    "\n",
    "ax1.set_xlabel(xlabels[0])\n",
    "ax1.set_ylabel(ylabels[0])\n",
    "ax1.hist(data_refine[0], range=ranges[0], bins=20, histtype='step', \n",
    "         weights=weight_refine)\n",
    "ax1.hist(data_raw[0], range=ranges[0], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'))\n",
    "\n",
    "ax2.set_xlabel(xlabels[1])\n",
    "ax2.set_ylabel(ylabels[1])\n",
    "ax2.hist(data_refine[1], range=ranges[1], bins=20, histtype='step', \n",
    "         weights=weight_refine,label=\"Refinery\")\n",
    "ax2.hist(data_raw[1], range=ranges[1], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'),label=\"Raw\")\n",
    "ax2.legend(bbox_to_anchor=(0.6, 0.95), loc=2, borderaxespad=0.)\n",
    "\n",
    "ax3.set_xlabel(xlabels[2])\n",
    "ax3.set_ylabel(ylabels[2])\n",
    "ax3.hist(data_refine[2], range=ranges[2], bins=20, histtype='step', \n",
    "         weights=weight_refine)\n",
    "ax3.hist(data_raw[2], range=ranges[2], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'))\n",
    "\n",
    "ax4.set_xlabel(xlabels[3])\n",
    "ax4.set_ylabel(ylabels[3])\n",
    "ax4.hist(data_refine[3], range=ranges[3], bins=20, histtype='step', \n",
    "         weights=weight_refine)\n",
    "ax4.hist(data_raw[3], range=ranges[3], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quality Test B : Compare Refinery and Raw Distributiosn for Different Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate two samples A and B, one based on thetaA and one on thetaB. Analyse the one from thetaA with MadMiner and put out refinery.extract_samples_test(theta=thetaB). Compare the distributions to those from the sample originally based on thetaB. This also checks the morphing in a non-trivial way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define Parameter Point\n",
    "point = np.array([0.,0.])\n",
    "\n",
    "# Raw data\n",
    "refineryB = Refinery('datasave/madminer_example_shuffled_runB.h5', debug=False)\n",
    "\n",
    "data_raw, weight_raw = refineryB.extract_raw_data()\n",
    "weight_raw = weight_raw[:,5]\n",
    "data_raw = data_raw.T\n",
    "\n",
    "# Refined data\n",
    "refineryA = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=False)\n",
    "\n",
    "data_refine, _ = refineryA.extract_samples_test(\n",
    "    theta=constant_morphing_theta(point),\n",
    "    n_samples=300000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='test'\n",
    ")\n",
    "\n",
    "data_refine = data_refine.T\n",
    "weight_refine = sum(weight_raw) / len(data_refine[0]) * np.ones_like(data_refine[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some plotting\n",
    "xlabels = [r'$p_{T,e}$ [GeV]', r'$p_{T,\\mu}$ [GeV]', r'$\\Delta \\eta_{\\ell\\ell}$', r'$\\Delta \\phi_{\\ell\\ell}$']\n",
    "ylabels = [r'$d\\sigma/dp_{T,e}$ [pb/bin]', r'$d\\sigma/p_{T,\\mu}$ [pb/bin]', r'$d\\sigma/\\Delta \\eta_{\\ell\\ell} [pb/bin]$', r'$d\\sigma/\\Delta \\phi_{\\ell\\ell} [pb/bin]$']\n",
    "ranges = [(0., 500.), (0., 500.), (0.,3.), (0.,6.2)]\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "f.set_size_inches(11,8)\n",
    "\n",
    "ax1.set_xlabel(xlabels[0])\n",
    "ax1.set_ylabel(ylabels[0])\n",
    "ax1.hist(data_refine[0], range=ranges[0], bins=20, histtype='step', \n",
    "         weights=weight_refine)\n",
    "ax1.hist(data_raw[0], range=ranges[0], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'))\n",
    "\n",
    "ax2.set_xlabel(xlabels[1])\n",
    "ax2.set_ylabel(ylabels[1])\n",
    "ax2.hist(data_refine[1], range=ranges[1], bins=20, histtype='step', \n",
    "         weights=weight_refine,label=\"Refinery\")\n",
    "ax2.hist(data_raw[1], range=ranges[1], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'),label=\"Raw\")\n",
    "ax2.legend(bbox_to_anchor=(0.6, 0.95), loc=2, borderaxespad=0.)\n",
    "\n",
    "ax3.set_xlabel(xlabels[2])\n",
    "ax3.set_ylabel(ylabels[2])\n",
    "ax3.hist(data_refine[2], range=ranges[2], bins=20, histtype='step', \n",
    "         weights=weight_refine)\n",
    "ax3.hist(data_raw[2], range=ranges[2], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'))\n",
    "\n",
    "ax4.set_xlabel(xlabels[3])\n",
    "ax4.set_ylabel(ylabels[3])\n",
    "ax4.hist(data_refine[3], range=ranges[3], bins=20, histtype='step', \n",
    "         weights=weight_refine)\n",
    "ax4.hist(data_raw[3], range=ranges[3], bins=20, histtype='step', \n",
    "         weights=weight_raw, linestyle=('dotted'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quality Test C : Compare Joint Ratios and Joint Scores? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the joint score components can be reproduced by the joint ratio:  `t(x,z|th0)_i = log[r(x,z|th1,th0)]/(th1_i-th0_i)` for two close th0 and th1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Refinery and load data\n",
    "refinery = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "#Calculate t and r \n",
    "point0 = np.array([1.1,0])\n",
    "point1 = np.array([0,0])\n",
    "x, theta0, theta1, y, r_xz, t_xz = refinery.extract_samples_train_ratio(\n",
    "    theta0=constant_morphing_theta(point0),\n",
    "    theta1=constant_morphing_theta(point1),\n",
    "    n_samples=400,\n",
    "    folder='./datasave/samples',\n",
    "    filename='train_rascal'\n",
    ")\n",
    "\n",
    "#Calculate Score:\n",
    "n_events = len(x)\n",
    "n_thetas = len(theta0[0])\n",
    "\n",
    "score_refinery = np.zeros( (n_thetas ,n_events) )\n",
    "score_check    = np.zeros( (n_thetas ,n_events) )\n",
    "for ith in range(0,n_thetas):\n",
    "    for iev in range(0,n_events):\n",
    "#        if y[iev]!=0: \n",
    "#            continue\n",
    "        score_refinery[ith][iev] = t_xz[iev][ith]\n",
    "#        score_check[ith][iev]    = (r_xz[iev][0]-1.)/(theta0[iev][ith]-theta1[iev][ith])   \n",
    "        score_check[ith][iev]    = log(r_xz[iev][0])/(theta0[iev][ith]-theta1[iev][ith])   \n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.scatter(score_refinery[0], score_check[0],  c=\"g\", alpha=0.5)\n",
    "plt.scatter(score_refinery[1], score_check[1],  c=\"b\", alpha=0.5)\n",
    "plt.xlabel(\"t[z,z|th0]_i\")\n",
    "plt.ylabel(\"log(r[x,z|th1,th0])/(th1-th0)_i\")\n",
    "plt.title('th0=('+str(point0[0])+','+str(point0[1])+'),   th1=('+str(point1[0])+','+str(point1[1])+')')\n",
    "plt.xlim(-0.0005, 0.0005)\n",
    "plt.ylim(-0.0005, 0.0005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Bug Report: Look at distribution of theta0 from refinery.extract_samples_train_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is that supposed to be like this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinery = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, theta0, theta1, y, r_xz, t_xz = refinery.extract_samples_train_ratio(\n",
    "    theta0=random_morphing_thetas(None, [('gaussian', 0., 0.5), ('flat', -0.5, 0.5)]),\n",
    "    theta1=constant_benchmark_theta('sm'),\n",
    "    n_samples=5000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='train_rascal'\n",
    ")\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.hist(theta0, range=(-1,1), bins=20, histtype='step', normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test D: Reweight distributions by r_xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the output from refinery.extract_samples_train_ratio(theta0, theta1), weight each y=1 sample with r_xz, and compare the distribution of this weighted y=1 sample to the (unweighted) distribution of the y=0 sample. They should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:35  \n",
      "20:35  ------------------------------------------------------------\n",
      "20:35  |                                                          |\n",
      "20:35  |  MadMiner                                                |\n",
      "20:35  |                                                          |\n",
      "20:35  |  Version from July 24, 2018                              |\n",
      "20:35  |                                                          |\n",
      "20:35  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "20:35  |                                                          |\n",
      "20:35  ------------------------------------------------------------\n",
      "20:35  \n",
      "20:35  \n",
      "    \n",
      "                                                      @ @ @ @   @ @ @ @                                \n",
      "                                                     @. . . . @ . . . . @                              \n",
      "                                                     @. . . . . . . . . @                              \n",
      "                   @@@@@@@@@@@@@@@                  @. . . . . . . . . . @                             \n",
      "              @@@@@///////////////@@@@      @@@@    @////////////////////@    @@@@                     \n",
      "         @@@@///////////@@@@@            @.......@ @//////////////////////@ @.......@                  \n",
      "      @@//////@@@@@@@///@               @............@@@@@@@@@@@@@@@@@@...............@                \n",
      "     @@@@@@@         @///@             @...............................................@               \n",
      "                     @///@             @................******....****.................@               \n",
      "                      @//@             @................-----**.._____.................@               \n",
      "                      @///@             @............./       \\*/     \\....,..........@                \n",
      "                      @///@              @...........|         |       |.............@                 \n",
      "                       @//@                @.........|       * |\\ *    |..........@                    \n",
      "                       @///@                   @@@@...\\       /..\\ __ / @@@@@@                         \n",
      "                       @///@                  @,,,,,,@  -----,%%%%%.     @.,,,,,@                      \n",
      "                        @//@               @,,,,,,,,,@    %,,     ,,%    @.,,,,,,,,@                   \n",
      "                        @///@            @,,,,,,,,,,@     %,,,   ,,,%    @,,,,,,,,,,@                  \n",
      "                        @///@           @,,,,,,,,,,,,@@@@@ %,,,,,,,% @@@@@,,,,,,,,,,,@                 \n",
      "                         @//@           @,,,,,,,,,,,,,,,,,,%%%%%%%,,,,,,,,,,,,,,,,,,,@                 \n",
      "                         @///@          @,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,@                 \n",
      "                         @///@_        @,,,,,,,,,,,,,,,----------------,,,,,,,,,,,,,,,,@       /\\ ___  \n",
      "                          @@@(  )      @,,,,,,,\\,,/----,,,,,,,,,,,,,,,,----\\,,/,,,,,,,,@      /  (___) \n",
      "                         (___) ) )    @**,,,,,,,\\-,,,,,,,,,,,,,,,,,,,,,,,,,,-/,,,,,,,,,,@    (  \\_(___)\n",
      "                         (___)_)  )@@@@&********,\\,,,,,,,,,,,,,,,,,,,,,,,,,,/,,*******&@@@@@@(    (___)\n",
      "                         (____)@  )%%%%%&*******,,,,,,,,,,,,,,,,,,,,,,,,,,,,********&&%%%%%%%( ___(___)\n",
      "                         (____)@__)@@@@%%%&*************,,,,,,,,,,,,,**************&%%%%@@@@@@@        \n",
      "                           @///@      @%%%%&***************************************&%%%%@              \n",
      "                            @//@      @%%%%%&&&&&&***************************&&&&&&%%%%%%@             \n",
      "                            @///@    @%%%%%%%%%%%%&*************************&%%%%%%%%%%%%%@            \n",
      "                            @@@@@    @%%%%%%%%%%%%%%&&&&&&&&&&&&&&&&&&&&&&&&%%%%%%%%%%%%%%@            \n",
      "                                    @%%%%%%%%%%%%%%%%%%%%%%%%@%%%@%%%%%%%%%%%%%%%%%%%%%%%%%@           \n",
      "                                    @%%%%%%%%%%%%%%%%%%%%%%%%@%%%@%%%%%%%%%%%%%%%%%%%%%%%%%@           \n",
      "                                    @%%%%%%%%%%%%%%%%%%%%%%%%@%%%@%%%%%%%%%%%%%%%%%%%%%%%%%@           \n",
      "                                    @%%%%%%%%%%%%%%%%%%%%%%%%@%%%@%%%%%%%%%%%%%%%%%%%%%%%%%@           \n",
      "                                    @%%%%%%%%%%%%%%%%%%%%%-----------%%%%%%%%%%%%%%%%%%%%%%@           \n",
      "                                    @###############%%%%/.............\\%%%%################@           \n",
      "                                    @##################|...............|###################@           \n",
      "                                     @#################|...............|##################@            \n",
      "                                      @((((#############\\............./##############((((@             \n",
      "                                       @((((((((((((((((#\\___________/#(((((((((((((((((@              \n",
      "                                          @((((((((((((((((##########((((((((((((((((@                 \n",
      "                                             @((((((((((((((((((((((((((((((((((((@                    \n",
      "                                                @@@@@@@@((((((((((((((((@@@@@@@@                       \n",
      "                                                @##%%%%@                @%%%%##@                       \n",
      "                                                @######@                @######@                       \n",
      "                                             @@########@                @########@@                    \n",
      "                                          @#######@@@@@@                @@@@@@#######@                 \n",
      "                                  ........@@@@@@@@@..@@@................@@@..@@@@@@@@@........         \n",
      "    \n",
      "    \n",
      "20:35  Loading data from datasave/madminer_example_shuffled_runA.h5\n",
      "20:35  Found 2 parameters:\n",
      "20:35     CWL2 (LHA: dim6 2, maximal power in squared ME: 2, range: (-10.0, 10.0))\n",
      "20:35     CPWL2 (LHA: dim6 5, maximal power in squared ME: 2, range: (-10.0, 10.0))\n",
      "20:35  Found 6 benchmarks:\n",
      "20:35     sm: CWL2 = 0.00e+00, CPWL2 = 0.00e+00\n",
      "20:35     bsm1: CWL2 = 4.00, CPWL2 = 0.00e+00\n",
      "20:35     bsm2: CWL2 = -7.64e+00, CPWL2 = -7.01e+00\n",
      "20:35     bsm3: CWL2 = 3.29, CPWL2 = -9.86e+00\n",
      "20:35     bsm4: CWL2 = -8.68e+00, CPWL2 = 6.87\n",
      "20:35     bsm5: CWL2 = 8.08, CPWL2 = 9.50\n",
      "20:35  Found 4 observables: pt_e1, pt_mu1, delta_eta_ll, delta_phi_ll\n",
      "20:35  Found 562576 events\n",
      "20:35  Found morphing setup with 6 components\n",
      "20:35  Extracting training sample for ratio-based methods. Numerator hypothesis: ('theta', array([0., 0.])), denominator hypothesis: ('theta', array([100., 100.]))\n",
      "20:35  Augmented data requested:\n",
      "20:35    Joint ratio, num sampling None, den auxiliary None;\n",
      "Num matrix:\n",
      "sampling\n",
      "Den matrix:\n",
      "auxiliary\n",
      "20:35    Joint score, at sampling None;\n",
      "Num matrix:\n",
      "sampling_gradient\n",
      "Den matrix:\n",
      "sampling\n",
      "20:35  Sampling and auxiliary thetas before balancing:\n",
      "20:35    sampling thetas:  [('morphing', array([0., 0.]))]\n",
      "20:35    auxiliary thetas: [('morphing', array([100., 100.]))]\n",
      "20:35  Sampling and auxiliary thetas after balancing:\n",
      "20:35    sampling thetas:  [('morphing', array([0., 0.]))]\n",
      "20:35    auxiliary thetas: [('morphing', array([100., 100.]))]\n",
      "20:35  New theta configuration\n",
      "20:35    Sampling theta: morphing, [0. 0.]\n",
      "20:35    Auxiliary theta: morphing, [100. 100.]\n",
      "20:35    # samples: 50000\n",
      "20:35  xsec for this sampling theta: (10.82547378540039 +/- 0.017262301347609924) pb\n",
      "20:35  Cumulative probability (should be close to 1): 1.0005832870968094\n",
      "20:35  Augmented data requested:\n",
      "20:35    Joint ratio, num auxiliary None, den sampling None;\n",
      "Num matrix:\n",
      "auxiliary\n",
      "Den matrix:\n",
      "sampling\n",
      "20:35    Joint score, at auxiliary None;\n",
      "Num matrix:\n",
      "auxiliary_gradient\n",
      "Den matrix:\n",
      "auxiliary\n",
      "20:35  Sampling and auxiliary thetas before balancing:\n",
      "20:35    sampling thetas:  [('morphing', array([100., 100.]))]\n",
      "20:35    auxiliary thetas: [('morphing', array([0., 0.]))]\n",
      "20:35  Sampling and auxiliary thetas after balancing:\n",
      "20:35    sampling thetas:  [('morphing', array([100., 100.]))]\n",
      "20:35    auxiliary thetas: [('morphing', array([0., 0.]))]\n",
      "20:35  New theta configuration\n",
      "20:35    Sampling theta: morphing, [100. 100.]\n",
      "20:35    Auxiliary theta: morphing, [0. 0.]\n",
      "20:35    # samples: 50000\n",
      "20:35  xsec for this sampling theta: (6.269534490234719 +/- 3.8871599307431084) pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:35  Warning: large statistical uncertainty on the total cross section for theta = [100. 100.]: (6.269534490234719 +/- 3.8871599307431084) pb\n",
      "20:35  Cumulative probability (should be close to 1): 0.8291281649292812\n",
      "20:35  After full pass through event files, 8505 / 50000 samples not found, u = [0.93252455 0.83574171 0.93643994 ... 0.94984653 0.95035203 0.88350748]\n",
      "20:35  Cumulative probability (should be close to 1): 0.8291281649292812\n",
      "20:35  After full pass through event files, 1439 / 50000 samples not found, u = [0.90713893 0.86653704 0.86052325 ... 0.85417664 0.96128387 0.98222906]\n",
      "20:35  Cumulative probability (should be close to 1): 0.8291281649292812\n",
      "20:35  After full pass through event files, 245 / 50000 samples not found, u = [0.96101867 0.96251179 0.85846142 0.9647317  0.92659567 0.96002216\n",
      " 0.95428341 0.98263077 0.98051691 0.83388612 0.96706255 0.98921201\n",
      " 0.97102357 0.92963269 0.86238893 0.96532166 0.99900305 0.94627098\n",
      " 0.97419969 0.86448372 0.97915481 0.88446812 0.94358939 0.96808338\n",
      " 0.94408823 0.91196178 0.84816726 0.89850483 0.93458863 0.86649223\n",
      " 0.98976441 0.88829337 0.88303807 0.97245083 0.98079912 0.87973163\n",
      " 0.94995969 0.84231969 0.99388954 0.83757258 0.90932006 0.97381407\n",
      " 0.86889056 0.97875957 0.96298521 0.84677981 0.94523377 0.91123704\n",
      " 0.83281189 0.95369881 0.898552   0.97840986 0.90726468 0.8314688\n",
      " 0.88447963 0.90251096 0.88067837 0.99243075 0.98977083 0.84168367\n",
      " 0.90862111 0.89883464 0.85629376 0.99942826 0.89350172 0.92658618\n",
      " 0.94422457 0.86477259 0.94687658 0.92273337 0.89891804 0.8407236\n",
      " 0.86805853 0.88044331 0.84046095 0.85754256 0.88979912 0.96844293\n",
      " 0.86959734 0.92139958 0.84234425 0.99601438 0.83185218 0.90640756\n",
      " 0.91180796 0.9693697  0.86638568 0.95988261 0.84903284 0.90272819\n",
      " 0.90404022 0.86614657 0.83379792 0.927413   0.96859846 0.98276908\n",
      " 0.82947972 0.91735122 0.90183965 0.92704232 0.90406749 0.93480924\n",
      " 0.98515611 0.8819977  0.92479802 0.89931797 0.84751267 0.93927839\n",
      " 0.91978697 0.9043728  0.95549026 0.89563325 0.95048213 0.92210219\n",
      " 0.87067751 0.82929486 0.92577406 0.89529483 0.88846038 0.90584035\n",
      " 0.9232961  0.83806491 0.93492532 0.89279098 0.8991624  0.91285122\n",
      " 0.92151104 0.90677028 0.96131656 0.8855437  0.94991059 0.99353176\n",
      " 0.86232755 0.9014655  0.85426361 0.94531017 0.90742351 0.96950347\n",
      " 0.88830628 0.8817485  0.86277983 0.9125371  0.95449922 0.89896768\n",
      " 0.94895162 0.84553236 0.86699734 0.8595655  0.96911671 0.92137551\n",
      " 0.841992   0.86477174 0.86441174 0.83185948 0.890042   0.92714543\n",
      " 0.97111711 0.95077254 0.94925113 0.95995867 0.86079588 0.97778517\n",
      " 0.8897924  0.91779316 0.89660172 0.86339364 0.99748053 0.85459238\n",
      " 0.92852751 0.84949449 0.99630829 0.93226895 0.97796799 0.83761708\n",
      " 0.96372016 0.90765795 0.9882565  0.9312269  0.84260173 0.89811847\n",
      " 0.95727649 0.94450204 0.90201381 0.99596707 0.89978528 0.99119548\n",
      " 0.87400411 0.92916602 0.8408669  0.98891874 0.9385432  0.86014251\n",
      " 0.83188849 0.85046325 0.91763583 0.9084418  0.86580021 0.95358672\n",
      " 0.90259566 0.95878948 0.9488442  0.99817157 0.88505366 0.91468219\n",
      " 0.83807376 0.88853385 0.87558416 0.83400769 0.93202858 0.93274571\n",
      " 0.96156873 0.91141725 0.93016578 0.97089915 0.86943281 0.85817793\n",
      " 0.84102828 0.86599887 0.89459244 0.97152186 0.90123101 0.94555883\n",
      " 0.8340193  0.88930578 0.91966046 0.83582465 0.87387244 0.98697387\n",
      " 0.95197075 0.90987879 0.9801924  0.9592801  0.87391146 0.89295542\n",
      " 0.87622247 0.91604384 0.8354111  0.85804543 0.99076698 0.84870033\n",
      " 0.9276877  0.90887539 0.83560205 0.86287832 0.94790557]\n",
      "20:35  Cumulative probability (should be close to 1): 0.8291281649292812\n",
      "20:35  After full pass through event files, 42 / 50000 samples not found, u = [0.96504603 0.83260023 0.83189285 0.84435921 0.83632898 0.92472235\n",
      " 0.86130497 0.93245982 0.83323716 0.95676026 0.8792834  0.83224153\n",
      " 0.89593516 0.92115095 0.91454697 0.9032531  0.86158506 0.93761976\n",
      " 0.99850102 0.99211073 0.97477876 0.87465246 0.91155946 0.90115143\n",
      " 0.92790281 0.98006638 0.90771322 0.86956884 0.9512714  0.87517394\n",
      " 0.97139456 0.89119901 0.86579692 0.88176906 0.90831948 0.95230068\n",
      " 0.95682334 0.92466286 0.88418878 0.92547633 0.87709877 0.90273941]\n",
      "20:35  Cumulative probability (should be close to 1): 0.8291281649292812\n",
      "20:35  After full pass through event files, 7 / 50000 samples not found, u = [0.82988885 0.98130956 0.94962591 0.84804029 0.95266953 0.97612584\n",
      " 0.90330709]\n",
      "20:35  Cumulative probability (should be close to 1): 0.8291281649292812\n",
      "20:35  After full pass through event files, 3 / 50000 samples not found, u = [0.95880778 0.84802682 0.98053769]\n",
      "20:35  Cumulative probability (should be close to 1): 0.8291281649292812\n"
     ]
    }
   ],
   "source": [
    "#Setup Refinery and load data\n",
    "refinery = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=True)\n",
    "\n",
    "#Calculate t and r \n",
    "point0 = np.array([0.,0])\n",
    "point1 = np.array([100,100.])\n",
    "x, theta0, theta1, y, r_xz, t_xz = refinery.extract_samples_train_ratio(\n",
    "    theta0=constant_morphing_theta(point0),\n",
    "    theta1=constant_morphing_theta(point1),\n",
    "    n_samples=100000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='train_rascal'\n",
    ")\n",
    "\n",
    "#_ , raw_weights_0 = refinery.extract_raw_data(theta=point0)\n",
    "#_ , raw_weights_1 = refinery.extract_raw_data(theta=point1)\n",
    "\n",
    "#Split y=0,1\n",
    "x_y0=x[y==0]\n",
    "x_y1=x[y==1]\n",
    "r_xz_y0=r_xz[y==0]\n",
    "r_xz_y1=r_xz[y==1]\n",
    "\n",
    "# Data + Weights\n",
    "data_y0   = x_y0.T\n",
    "#weight_y0 = sum(raw_weights_0) / len(data_y0[0]) * np.ones_like(data_y0[0])    \n",
    "        \n",
    "data_y1   = x_y1.T\n",
    "#weight_y1 = sum(raw_weights_1) / len(data_y1[0]) * np.ones_like(data_y1[0])    \n",
    "#reweight_y1 = sum(raw_weights_1) / len(data_y1[0]) * r_xz_y1\n",
    "reweight_y1 = r_xz_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some plotting\n",
    "xlabels = [r'$p_{T,e}$ [GeV]', r'$p_{T,\\mu}$ [GeV]', r'$\\Delta \\eta_{\\ell\\ell}$', r'$\\Delta \\phi_{\\ell\\ell}$']\n",
    "ylabels = [r'$d\\sigma/dp_{T,e}$ [pb/bin]', r'$d\\sigma/p_{T,\\mu}$ [pb/bin]', r'$d\\sigma/\\Delta \\eta_{\\ell\\ell} [pb/bin]$', r'$d\\sigma/\\Delta \\phi_{\\ell\\ell} [pb/bin]$']\n",
    "ranges = [(0., 500.), (0., 500.), (0.,3.), (0.,6.2)]\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "f.set_size_inches(11,8)\n",
    "\n",
    "ax1.set_xlabel(xlabels[0])\n",
    "ax1.set_ylabel(ylabels[0])\n",
    "ax1.hist(data_y0[0], range=ranges[0], bins=20, histtype='step')\n",
    "         #weights=weight_y0)\n",
    "ax1.hist(data_y1[0], range=ranges[0], bins=20, histtype='step')\n",
    "         #weights=weight_y1, linestyle=('dotted'))\n",
    "ax1.hist(data_y1[0], range=ranges[0], bins=20, histtype='step', \n",
    "         weights=reweight_y1, linestyle=('dashed'))\n",
    "\n",
    "ax2.set_xlabel(xlabels[1])\n",
    "ax2.set_ylabel(ylabels[1])\n",
    "ax2.hist(data_y0[1], range=ranges[1], bins=20, histtype='step', \n",
    "         #weights=weight_y0,\n",
    "         label='y=0: th0=('+str(point0[0])+','+str(point0[1])+')')\n",
    "ax2.hist(data_y1[1], range=ranges[1], bins=20, histtype='step', \n",
    "         #weights=weight_y1,\n",
    "         linestyle=('dotted'),label='y=1: th1=('+str(point1[0])+','+str(point1[1])+')')\n",
    "ax2.hist(data_y1[1], range=ranges[1], bins=20, histtype='step', \n",
    "         weights=reweight_y1, linestyle=('dashed'),label='y=1: reweighted by r_xz')\n",
    "ax2.legend(bbox_to_anchor=(0.4, 0.95), loc=2, borderaxespad=0.)\n",
    "\n",
    "\n",
    "ax3.set_xlabel(xlabels[2])\n",
    "ax3.set_ylabel(ylabels[2])\n",
    "ax3.hist(data_y0[2], range=ranges[2], bins=20, histtype='step')\n",
    "         #weights=weight_y0)\n",
    "ax3.hist(data_y1[2], range=ranges[2], bins=20, histtype='step', \n",
    "         #weights=weight_y1,\n",
    "         linestyle=('dotted'))\n",
    "ax3.hist(data_y1[2], range=ranges[2], bins=20, histtype='step', \n",
    "         weights=reweight_y1, linestyle=('dashed'))\n",
    "\n",
    "ax4.set_xlabel(xlabels[3])\n",
    "ax4.set_ylabel(ylabels[3])\n",
    "ax4.hist(data_y0[3], range=ranges[3], bins=20, histtype='step')\n",
    "         #weights=weight_y0)\n",
    "ax4.hist(data_y1[3], range=ranges[3], bins=20, histtype='step', \n",
    "         #weights=weight_y1,\n",
    "         linestyle=('dotted'))\n",
    "ax4.hist(data_y1[3], range=ranges[3], bins=20, histtype='step', \n",
    "         weights=reweight_y1, linestyle=('dashed'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Bug2: check r_xz distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Refinery and load data\n",
    "refinery = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=False)\n",
    "\n",
    "\n",
    "#Calculate t and r \n",
    "point0 = np.array([0.,0])\n",
    "point1 = np.array([100.,100.])\n",
    "x, theta0, theta1, y, r_xz, t_xz = refinery.extract_samples_train_ratio(\n",
    "    #theta0=constant_benchmark_theta('bsm1'),\n",
    "    #theta1=constant_benchmark_theta('sm'),\n",
    "    theta0=constant_morphing_theta(point0),\n",
    "    theta1=constant_morphing_theta(point1),\n",
    "    n_samples=100000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='train_rascal'\n",
    ")\n",
    "\n",
    "#Split y=0,1\n",
    "r_xz_y0=r_xz[y==0]\n",
    "r_xz_y1=r_xz[y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.xlabel('r_xz')\n",
    "plt.ylabel('a.u.')\n",
    "plt.hist(r_xz_y0, range=(0.,2.), bins=20, histtype='step',normed=True,label='y=0')\n",
    "plt.hist(r_xz_y1, range=(0.,2.), bins=20, histtype='step',normed=True,linestyle=('dashed'),label='y=1')\n",
    "plt.legend(bbox_to_anchor=(0.4, 0.95), loc=2, borderaxespad=0.)\n",
    "plt.title('th0=bsm1,   th1=sm)')\n",
    "#plt.title('th0=('+str(point0[0])+','+str(point0[1])+'),   th1=('+str(point1[0])+','+str(point1[1])+')')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Just plot distributions for different thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Refinery and load data\n",
    "refinery = Refinery('datasave/madminer_example_shuffled_runA.h5', debug=False)\n",
    "\n",
    "#Calculate t and r \n",
    "point1 = np.array([0.,0])\n",
    "point2 = np.array([100.,100.])\n",
    "\n",
    "x1, theta1 = refinery.extract_samples_test(\n",
    "    theta=constant_morphing_theta(point1),\n",
    "    n_samples=100000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='test'\n",
    ")\n",
    "\n",
    "x2, theta2 = refinery.extract_samples_test(\n",
    "    theta=constant_morphing_theta(point2),\n",
    "    n_samples=100000,\n",
    "    folder='./datasave/samples',\n",
    "    filename='test'\n",
    ")\n",
    "#_ , raw_weights_2 = refinery.extract_raw_data(theta=point2)\n",
    "#_ , raw_weights_1 = refinery.extract_raw_data(theta=point1)\n",
    "\n",
    "# Data + Weights\n",
    "data_x1   = x1.T\n",
    "#weight_x1 = sum(raw_weights_1) / len(data_x1[0]) * np.ones_like(data_x1[0])   \n",
    "\n",
    "data_x2   = x2.T\n",
    "#weight_x2 = sum(raw_weights_2) / len(data_x2[0]) * np.ones_like(data_x2[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some plotting\n",
    "xlabels = [r'$p_{T,e}$ [GeV]', r'$p_{T,\\mu}$ [GeV]', r'$\\Delta \\eta_{\\ell\\ell}$', r'$\\Delta \\phi_{\\ell\\ell}$']\n",
    "ylabels = [r'$d\\sigma/dp_{T,e}$ [pb/bin]', r'$d\\sigma/p_{T,\\mu}$ [pb/bin]', r'$d\\sigma/\\Delta \\eta_{\\ell\\ell} [pb/bin]$', r'$d\\sigma/\\Delta \\phi_{\\ell\\ell} [pb/bin]$']\n",
    "ranges = [(0., 500.), (0., 500.), (0.,3.), (0.,6.2)]\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "f.set_size_inches(11,8)\n",
    "\n",
    "ax1.set_xlabel(xlabels[0])\n",
    "ax1.set_ylabel(ylabels[0])\n",
    "ax1.hist(data_x1[0], range=ranges[0], bins=20, histtype='step')\n",
    "         #weights=weight_x1)\n",
    "ax1.hist(data_x2[0], range=ranges[0], bins=20, histtype='step', \n",
    "         #weights=weight_x2,\n",
    "         linestyle=('dotted'))\n",
    "\n",
    "ax2.set_xlabel(xlabels[1])\n",
    "ax2.set_ylabel(ylabels[1])\n",
    "ax2.hist(data_x1[1], range=ranges[1], bins=20, histtype='step', \n",
    "         #weights=weight_x1,\n",
    "         label='th1=('+str(point1[0])+','+str(point1[1])+')')\n",
    "ax2.hist(data_x2[1], range=ranges[1], bins=20, histtype='step', \n",
    "         #weights=weight_x2,\n",
    "         linestyle=('dotted'),label='th2=('+str(point2[0])+','+str(point2[1])+')')\n",
    "ax2.legend(bbox_to_anchor=(0.5, 0.95), loc=2, borderaxespad=0.)\n",
    "\n",
    "ax3.set_xlabel(xlabels[2])\n",
    "ax3.set_ylabel(ylabels[2])\n",
    "ax3.hist(data_x1[2], range=ranges[2], bins=20, histtype='step')\n",
    "         #weights=weight_x1)\n",
    "ax3.hist(data_x2[2], range=ranges[2], bins=20, histtype='step', \n",
    "         #weights=weight_x2,\n",
    "         linestyle=('dotted'))\n",
    "\n",
    "ax4.set_xlabel(xlabels[3])\n",
    "ax4.set_ylabel(ylabels[3])\n",
    "ax4.hist(data_x1[3], range=ranges[3], bins=20, histtype='step')\n",
    "         #weights=weight_x1)\n",
    "ax4.hist(data_x2[3], range=ranges[3], bins=20, histtype='step', \n",
    "         #weights=weight_x2,\n",
    "         linestyle=('dotted'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
