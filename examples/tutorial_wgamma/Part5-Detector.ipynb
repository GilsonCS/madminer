{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Detector Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first load all the python libraries again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "madminer_src_path = \"/Users/felixkling/Documents/GitHub/madminer\"\n",
    "sys.path.append(madminer_src_path)\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "% matplotlib inline\n",
    "\n",
    "from madminer.delphes import DelphesProcessor\n",
    "from madminer.sampling import combine_and_shuffle\n",
    "from madminer.utils.particle import MadMinerParticle\n",
    "\n",
    "from madminer.fisherinformation import FisherInformation\n",
    "from madminer.fisherinformation import project_information,profile_information\n",
    "\n",
    "from madminer.plotting import plot_fisher_information_contours_2d\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import constant_benchmark_theta, multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please enter here the path to your MG5 root directory. This notebook assumes that you installed Delphes and Pythia through MG5. \n",
    "\n",
    "**This needs to be updated by the user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_dir = '/Users/felixkling/work/MG5_aMC_v2_6_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.  Run detector simulation and extract observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `madminer.delphes` wraps around Delphes, a popular fast detector simulation. In addition to simulating the detector, it allows for the fast extraction of observables, which are saved in the MadMiner HDF5 file. The central object is an instance of the `DelphesProcessor` class, which has to be initialized with a MadMiner file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:32  \n",
      "20:32  ------------------------------------------------------------\n",
      "20:32  |                                                          |\n",
      "20:32  |  MadMiner v0.1.0                                         |\n",
      "20:32  |                                                          |\n",
      "20:32  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "20:32  |                                                          |\n",
      "20:32  ------------------------------------------------------------\n",
      "20:32  \n"
     ]
    }
   ],
   "source": [
    "dp = DelphesProcessor('data/madminer_example.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the DelphesProcessor object, one can add a number of HepMC event samples (the output of running MadGraph and Pythia) and have it run Delphes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:32  Running Delphes (/Users/felixkling/work/MG5_aMC_v2_6_2/Delphes) on event sample at mg_processes/wgamma/Events/run_01/tag_1_pythia8_events.hepmc.gz\n"
     ]
    }
   ],
   "source": [
    "dp.add_hepmc_sample(\n",
    "    'mg_processes/wgamma/Events/run_01/tag_1_pythia8_events.hepmc.gz',\n",
    "    sampled_from_benchmark='sm'\n",
    ")\n",
    "#dp.add_hepmc_sample(\n",
    "#    'mg_processes/background/Events/run_01/tag_1_pythia8_events.hepmc.gz',\n",
    "#    sampled_from_benchmark='sm'\n",
    "#)\n",
    "\n",
    "dp.run_delphes(\n",
    "    delphes_directory=mg_dir + '/Delphes',\n",
    "    delphes_card='cards/delphes_card.dat',\n",
    "    log_file='logs/wgamma/log_delphes.log',\n",
    "    initial_command='source ~/.bashrc'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the definition of observables through a name and a python expression. For the latter, you can use the objects `j[i]`, `e[i]`, `mu[i]`, `a[i]`, `met`, where the indices `i` refer to a ordering by the transverse momentum. All of these objects inherit from scikit-hep [LorentzVectors](http://scikit-hep.org/api/math.html#vector-classes), see the link for a documentation of their properties. In addition, they have `charge` and `pdg_id` properties.\n",
    "\n",
    "There is an optional keyword `required`. If `required=True`, we will only keep events where the observable can be parsed, i.e. all involved particles have been detected. If `required=False`, un-parseable observables will be filled with the value of another keyword `default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.add_observable('px_l', 'mu[0].px',required=True)\n",
    "dp.add_observable('px_v', 'met.px',required=True)\n",
    "dp.add_observable('px_a', 'a[0].px',required=True)\n",
    "\n",
    "dp.add_observable('py_l', 'mu[0].py',required=True)\n",
    "dp.add_observable('py_v', 'met.py',required=True)\n",
    "dp.add_observable('py_a', 'a[0].py',required=True)\n",
    "\n",
    "dp.add_observable('pz_l', 'mu[0].pz',required=True)\n",
    "dp.add_observable('pz_a', 'a[0].pz',required=True)\n",
    "\n",
    "dp.add_observable('e_l', 'mu[0].e',required=True)\n",
    "dp.add_observable('e_a', 'a[0].e',required=True)\n",
    "\n",
    "dp.add_observable('pt_l', 'mu[0].pt',required=True)\n",
    "dp.add_observable('pt_v', 'met.pt',required=True)\n",
    "dp.add_observable('pt_a', 'a[0].pt',required=True)\n",
    "\n",
    "dp.add_observable('eta_l', 'mu[0].eta',required=True)\n",
    "dp.add_observable('eta_a', 'a[0].eta',required=True)\n",
    "\n",
    "dp.add_observable('dphi_lv', 'mu[0].deltaphi(met)',required=True)\n",
    "dp.add_observable('dphi_la', 'mu[0].deltaphi(a[0])',required=True)\n",
    "dp.add_observable('dphi_va', 'met.deltaphi(a[0])',required=True)\n",
    "\n",
    "dp.add_observable('m_la', '(mu[0] + a[0]).m',required=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add cuts, again in parse-able strings. In addition to the objects discussed above, they can contain the observables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dp.add_cut('pt_a > 250.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `analyse_delphes_samples` then calculates all observables from the Delphes ROOT file(s) generated before and applies the cuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:36  Analysing Delphes sample mg_processes/wgamma/Events/run_01/tag_1_pythia8_events_delphes.root\n"
     ]
    }
   ],
   "source": [
    "dp.analyse_delphes_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the observables and the weights are then saved in the HDF5 file. It is possible to overwrite the same file, or to leave the original file intact and save all the data into a new file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.save('data/madminer_detector_with_data.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One side remark: For the detector simulation and calculation of observables, different users might have very different requirements. While a phenomenologist might be content with the fast detector simulation from Delphes, an experimental analysis might require the full simulation through Geant4. We therefore intend this part to be interchangeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce disk usage, you can generate several small event samples with the steps given above, and combine them now. Note that (for now) it is essential that all of them are generated with the same setup, including the same benchmark points / morphing basis!\n",
    "\n",
    "In our case we only have one sample, so this is not strictly necessary, but we still include it for completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_and_shuffle(\n",
    "    ['data/madminer_detector_with_data.h5'],\n",
    "    'data/madminer_detector_shuffled.h5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run MadMiner at Detector Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define the input file, the number of samples and *effective* number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = 'data/madminer_detector_with_data.h5'\n",
    "nsamples = 100000\n",
    "nsampleseff = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10a) Run the Data Augmentation and Machine Learning part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we once again augment the data and machine learning part again. Here  `n_samples` should be choosen similar to the effective number of events, which also depends on the cuts choosen earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SampleAugmenter(inputfile, debug=False)\n",
    "\n",
    "n_estimators = 5\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    x, theta, t_xz = sa.extract_samples_train_local(\n",
    "        theta=constant_benchmark_theta('sm'),\n",
    "        n_samples=nsampleseff,\n",
    "        folder='./data/samples_detector/',\n",
    "        filename='train{}'.format(i)\n",
    "    )\n",
    "\n",
    "x, theta, t_xz = sa.extract_samples_train_local(\n",
    "    theta=constant_benchmark_theta('sm'),\n",
    "    n_samples=nsampleseff,\n",
    "    folder='./data/samples_detector/',\n",
    "    filename='test',\n",
    "    switch_train_test_events=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the perform the ML part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleForge(estimators=n_estimators)\n",
    "ensemble.train_all(\n",
    "    method='sally',\n",
    "    x_filename=['data/samples_detector/x_train{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=['data/samples_detector/t_xz_train{}.npy'.format(i) for i in range(n_estimators)]\n",
    ")\n",
    "\n",
    "ensemble.save('models/samples_detector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10b) Obtain the Fisher Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the Fisher Info again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_parton = FisherInformation('data/madminer_example_shuffled.h5', debug=False)\n",
    "\n",
    "fi_ml_mean, fi_ml_covariance = fisher_parton.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    model_file='models/samples_ensemble',\n",
    "    unweighted_x_sample_file='data/samples_ensemble/x_test.npy',\n",
    "    luminosity=300*1000./nsamples\n",
    ")\n",
    "\n",
    "fi_metonly_mean, fi_metonly_covariance = fisher_parton.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    model_file='models/samples_metonly',\n",
    "    unweighted_x_sample_file='data/samples_ensemble/x_test.npy',\n",
    "    luminosity=300*1000./nsamples\n",
    ")\n",
    "\n",
    "fi_truth_mean, fi_truth_covariance = fisher_parton.calculate_fisher_information_full_truth(\n",
    "    theta=[0.,0.],\n",
    "    luminosity=300*1000./nsamples\n",
    ")\n",
    "\n",
    "fisher_detector = FisherInformation(inputfile, debug=False)\n",
    "\n",
    "fi_detector_mean, fi_detector_covariance = fisher_detector.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    model_file='models/samples_detector',\n",
    "    unweighted_x_sample_file='data/samples_detector/x_test.npy',\n",
    "    luminosity=300*1000.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_fisher_information_contours_2d(\n",
    "    [fi_ml_mean, fi_metonly_mean, fi_detector_mean,fi_truth_mean ],\n",
    "    [fi_ml_covariance, fi_metonly_covariance,fi_detector_covariance, fi_truth_covariance],\n",
    "    colors=[u'C0',u'C1',u'C2',\"black\"],\n",
    "    linestyles=[\"solid\",\"solid\",\"solid\",\"dashed\"],\n",
    "    inline_labels=[\"ML-all\",\"ML-MET\",\"ML-Detector\",\"truth\"],\n",
    "    xrange=(-15,15),\n",
    "    yrange=(-5,5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
