{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MadMiner example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we'll demonstrate how to use MadMiner to generate train and test samples for the ML methods introduced in [\"Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00013) and [\"A Guide to Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00020), both by Johann Brehmer, Gilles Louppe, Juan Pavez, and Kyle Cranmer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you execute this notebook, make sure you have running installations of MadGraph, Pythia, and Delphes. Note that at least for now, the MG-Pythia interface and Delphes require custom patches (available upon request). In addition, MadMiner and [DelphesMiner](https://github.com/johannbrehmer/delphesminer) have to be in your PYTHONPATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from madminer.goldmine import GoldMine\n",
    "from madminer.tools.plots import plot_2d_morphing_basis\n",
    "\n",
    "from delphesprocessor.delphesprocessor import DelphesProcessor\n",
    "\n",
    "from madminer.refinery import combine_and_shuffle\n",
    "from madminer.refinery import Refinery\n",
    "from madminer.refinery import constant_benchmark_theta, multiple_benchmark_thetas\n",
    "from madminer.refinery import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "\n",
    "from forge.forge import Forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please enter here the path to your MG5 root directory. This notebook assumes that you installed Delphes and Pythia through MG5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a `GoldMine` instance, the first important step is the definition of the parameter space. Each model parameter is characterized by a name as well as the LHA block and ID.\n",
    "\n",
    "If morphing is used, one also has to specify the maximal power with which the parameter contributes to the squared matrix element. For instance, a parameter that contributes only to one vertex, will typically have `morphing_max_power=2`, while a parameter that contributes to two vertices usually has `morphing_max_power=4`. Exceptions arise for instance when the interference effects between the SM and dimension-six operators are modelled, but the square of the dimension-six amplitude (subleading in 1/Lambda) is not taken into account, in which case `morphing_max_power=1`. Finally, the `parameter_range` argument defines the range of parameter values that are used for the automatic optimization of the morphing basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner = GoldMine()\n",
    "\n",
    "miner.add_parameter(\n",
    "    lha_block='dim6',\n",
    "    lha_id=2,\n",
    "    parameter_name='CWL2',\n",
    "    morphing_max_power=2,\n",
    "    parameter_range=(-10.,10.)\n",
    ")\n",
    "miner.add_parameter(\n",
    "    lha_block='dim6',\n",
    "    lha_id=5,\n",
    "    parameter_name='CPWL2',\n",
    "    morphing_max_power=2,\n",
    "    parameter_range=(-10.,10.)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define benchmark points (evaluation points for |M|^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the definition of all the points at which the weights (squared matrix elements) should be evaluated by MadGraph. We call these points \"benchmarks\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Set benchmarks by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can define benchmarks by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner.add_benchmark(\n",
    "    {'CWL2':0., 'CPWL2':0.},\n",
    "    'sm'\n",
    ")\n",
    "miner.add_benchmark(\n",
    "    {'CWL2':1., 'CPWL2':0.},\n",
    "    'bsm'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Benchmarks for morphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If morphing is used, the function `set_benchmarks_from_morphing` has to be called. With the option `keep_existing_benchmarks=True`, MadMiner will keep all the benchmark points defined beforehand and run a simple optimization algorithm to fix the remaining ones for the basis (which may be none). Otherwise, MadMiner will optimize the full basis and forget about all previously defined benchmark points. The argument `n_trials` determines the number of random candidate bases that the optimization algorithm goes through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner.set_benchmarks_from_morphing(\n",
    "    keep_existing_benchmarks=True,\n",
    "    n_trials=1000,\n",
    "    max_overall_power=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the resulting morphing basis and the \"morphing error\", i.e. the sum of squared morphing weights as a function of the parameter space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_2d_morphing_basis(\n",
    "    miner.morpher,\n",
    "    xlabel=r'$c_{W} / \\Lambda^2$ [TeV$^{-2}$]',\n",
    "    ylabel=r'$c_{\\tilde{W}} / \\Lambda^2$ [TeV$^{-2}$]',\n",
    "    xrange=(-10.,10),\n",
    "    yrange=(-10.,10.)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save settings and run MadGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter space, benchmark points, and morphing setup are saved in a HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner.save('data/madminer_example.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step, MadMiner starts MadGraph and Pythia to generate events and calculate the weights. You have to provide paths to the process card, run card, param card (the entries corresponding to the parameters of interest will be automatically adapted), and an empty reweight card.\n",
    "\n",
    "The `sample_benchmark` option can be used to specify which benchmark should be used for sampling. If it is not used, MadMiner will automatically use the benchmark that was added first. Finally, if MadGraph is supposed to run in a different Python environment or requires other setup steps, you can use the `initial_command` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner.run(\n",
    "    mg_directory=mg_dir,\n",
    "    proc_card_file='cards/proc_card.dat',\n",
    "    param_card_template_file='cards/param_card_template.dat',\n",
    "    reweight_card_template_file='cards/reweight_card_template.dat',\n",
    "    run_card_file='cards/run_card.dat',\n",
    "    pythia8_card_file='cards/pythia8_card.dat',\n",
    "    sample_benchmark='sm',\n",
    "    initial_command='source activate python2'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run detector simulation and extract observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detector simulation and calculation of observables is not part of MadMiner. The reason is that different users might have very different requirements here: while a phenomenologist might be content with the fast detector simulation from Delphes, an experimental analysis might require the full simulation through Geant4.\n",
    "\n",
    "We provide the DelphesMiner package, which wraps around Delphes and allows for the fast extraction of observables into the HDF5 file.\n",
    "\n",
    "Any user is free to replace the DelphesMiner step with a tool of their choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DelphesProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the DelphesProcessor object, one can add a number of HepMC event samples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.add_hepmc_sample('MG_process/Events/run_01/tag_1_pythia8_events.hepmc.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and have it run Delphes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.run_delphes(delphes_directory=mg_dir + '/Delphes',\n",
    "               delphes_card='cards/delphes_card.dat',\n",
    "               initial_command='source activate python2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the definition of observables through a name and a python expression. For the latter, you can use the objects `j[i]`, `e[i]`, `mu[i]`, `a[i]`, `met`, where the indices `i` refer to a ordering by the transverse momentum. All of these objects are scikit-hep [LorentzVectors](http://scikit-hep.org/api/math.html#vector-classes), see the link for a documentation of their properties.\n",
    "\n",
    "There is an optional keyword `required`. If `required=True`, we will only keep events where the observable can be parsed, i.e. all involved particles have been detected. If `required=False`, un-parseable observables will be filled with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.add_observable('pt_j1', 'j[0].pt', required=True)\n",
    "dm.add_observable('pt_j2', 'j[1].pt', required=True)\n",
    "dm.add_observable('delta_phi_jj', 'abs(j[0].phi() - j[1].phi())', required=True)\n",
    "dm.add_observable('delta_eta_jj', 'abs(j[0].eta - j[1].eta)', required=True)\n",
    "dm.add_observable('m_jj', '(j[0] + j[1]).m', required=True)\n",
    "dm.add_observable('n_jets', 'len(j)', required=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `analyse_delphes_samples` extracts all these observables from the Delphes ROOT file(s) generated before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.analyse_delphes_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the observables and the weights are then saved in the HDF5 file. It is possible to overwrite the same file, or to leave the original file intact and save all the data into a new file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.save('data/madminer_example_with_data.h5', 'data/madminer_example.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to check some distributions at this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "for weights in dm.weights:\n",
    "    plt.hist(dm.observations['pt_j1'], range=(0.,800.), bins=20, histtype='step', weights=weights)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combine and shuffle different event samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce disk usage, you can generate several small event samples with the steps given above, and combine them now. Note that (for now) it is essential that all of them are generated with the same setup, including the same benchmark points / morphing basis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_and_shuffle(\n",
    "    ['data/madminer_example_with_data.h5'],\n",
    "    'data/madminer_example_shuffled.h5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make (unweighted) training and test samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last important MadMiner class is the `Smithy`. From all the data we have in the HDF5 file now, it extracts unweighted samples including the augmented data (\"gold\") that is needed as training and evaluation data for the Machine Learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refinery = Refinery('data/madminer_example_shuffled.h5', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Refinery` class defines four different high-level functions to generate train or test samples:\n",
    "- `extract_samples_train_plain()`, which only saves observations x, for instance for histograms or ABC;\n",
    "- `extract_samples_train_local()` for methods like SALLY and SALLINO;\n",
    "- `extract_samples_train_ratio()` for techniques like CARL, ROLR, CASCAL, and RASCAL; and\n",
    "- `extract_samples_test()` for the evaluation of any method.\n",
    "\n",
    "For the arguments `theta`, `theta0`, or `theta1`, you can use the helper functions `constant_benchmark_theta()`, `multiple_benchmark_thetas()`, `constant_morphing_theta()`, `multiple_morphing_thetas()`, and `random_morphing_thetas()`, all defined in the `smithy` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, theta, t_xz = refinery.extract_samples_train_local(\n",
    "    theta=constant_morphing_theta(np.array([1.,0.])),\n",
    "    n_samples=1000,\n",
    "    folder='./data/samples',\n",
    "    filename='train_sally'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, theta0, theta1, y, r_xz, t_xz = refinery.extract_samples_train_ratio(\n",
    "    theta0=random_morphing_thetas(None, [('gaussian', 0., 5.), ('flat', -10., 10.)]),\n",
    "    theta1=constant_benchmark_theta('sm'),\n",
    "    n_samples=100000,\n",
    "    folder='./data/samples',\n",
    "    filename='train_rascal'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, theta = refinery.extract_samples_test(\n",
    "    theta=constant_benchmark_theta('sm'),\n",
    "    n_samples=10000,\n",
    "    folder='./data/samples',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some distributions and correlations in this test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "labels = [r'$p_{T,j1}$ [GeV]', r'$p_{T,j2}$ [GeV]', r'$\\Delta \\phi_{jj}$', r'$\\Delta \\eta_{jj}$', r'$m_{jj}$', r'$n_{j}$']\n",
    "ranges = [(0., 300.), (0., 200.), (0.,6.2), (0.,8.), (0.,1500.), (1.,6.5)]\n",
    "\n",
    "_ = corner.corner(x, color='C0', labels=labels, range=ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging, you can also access the full list of observables and benchmark weights (same units as in the LHE file) in the HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x, all_weights = refinery.extract_raw_data(theta=[0.0,0.1])\n",
    "\n",
    "print(all_x)\n",
    "print(all_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train likelihood ratio estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to build the likelihood ratio estimators. The central object for this is the `Forge` class. It defines functions that train, save, load, and evaluate the neural networks that estimate the likelihood ratio.\n",
    "\n",
    "Here we will use the RASCAL method described in [\"Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00013) and [\"A Guide to Constraining Effective Field Theories With Machine Learning\"](https://arxiv.org/abs/1805.00020). Other soon-to-be implemented methods include CARL, CASCAL, and ROLR described in the same publications, as well as ALICE and ALICES which are introduced in a paper that will soon hit the arXiv. SALLY and SALLINO will follow at some point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:29  \n",
      "21:29  ------------------------------------------------------------\n",
      "21:29  |                                                          |\n",
      "21:29  |  Forge                                                   |\n",
      "21:29  |                                                          |\n",
      "21:29  |  Version from July 31, 2018                              |\n",
      "21:29  |                                                          |\n",
      "21:29  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "21:29  |                                                          |\n",
      "21:29  ------------------------------------------------------------\n",
      "21:29  \n",
      "21:29  Starting training\n",
      "21:29    Method:                 rolr\n",
      "21:29    Training data: theta at data/samples/theta0_train_rascal.npy\n",
      "21:29                   x at     data/samples/x_train_rascal.npy\n",
      "21:29                   y at     data/samples/y_train_rascal.npy\n",
      "21:29                   r_xz at  data/samples/r_xz_train_rascal.npy\n",
      "21:29                   t_xz at  data/samples/t_xz_train_rascal.npy\n",
      "21:29    Method:                 rolr\n",
      "21:29    Hidden layers:          (100, 100, 100)\n",
      "21:29    Activation function:    tanh\n",
      "21:29    alpha:                  100.0\n",
      "21:29    Batch size:             64\n",
      "21:29    Epochs:                 10\n",
      "21:29    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "21:29    Early stopping:         True\n",
      "21:29  Loading training data\n",
      "21:29  Found 10000 samples with 2 parameters and 6 observables\n",
      "21:29  Creating model for method rolr\n",
      "21:29  Training model\n",
      "21:29    Epoch 1: train loss 11.25 ([11.2499097]), validation loss 0.28 ([0.28223451]) (*)\n",
      "21:29    Epoch 2: train loss 11.25 ([11.25008291]), validation loss 0.28 ([0.28189695]) (*)\n",
      "21:29    Epoch 3: train loss 11.25 ([11.25004348]), validation loss 0.28 ([0.28201751])\n",
      "21:29    Epoch 4: train loss 11.25 ([11.25227714]), validation loss 0.28 ([0.28098381]) (*)\n",
      "21:30    Epoch 5: train loss 11.23 ([11.2281161]), validation loss 0.31 ([0.30837302])\n",
      "21:30    Epoch 6: train loss 11.25 ([11.24909338]), validation loss 0.32 ([0.3192263])\n",
      "21:30    Epoch 7: train loss 11.24 ([11.23995988]), validation loss 0.30 ([0.29753054])\n",
      "21:30    Epoch 8: train loss 11.23 ([11.23416032]), validation loss 0.28 ([0.28017925]) (*)\n",
      "21:30    Epoch 9: train loss 11.23 ([11.22864354]), validation loss 0.29 ([0.28582354])\n",
      "21:30    Epoch 10: train loss 11.23 ([11.22716978]), validation loss 0.29 ([0.28754121])\n",
      "21:30  Early stopping after epoch 8, with loss 0.28 compared to final loss 0.29\n",
      "21:30  Finished training\n",
      "21:30  Saving settings to models/rascal_settings.json\n",
      "21:30  Saving state dictionary to models/rascal_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "forge = Forge(debug=True)\n",
    "\n",
    "forge.train(\n",
    "    method='rolr',\n",
    "    theta_filename='data/samples/theta0_train_rascal.npy',\n",
    "    x_filename='data/samples/x_train_rascal.npy',\n",
    "    y_filename='data/samples/y_train_rascal.npy',\n",
    "    r_xz_filename='data/samples/r_xz_train_rascal.npy',\n",
    "    t_xz_filename='data/samples/t_xz_train_rascal.npy',\n",
    "    alpha=100.,\n",
    "    n_epochs=10,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "forge.save('models/rascal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forge.evaluate(theta,x)` estimated the log likelihood ratio and the score for all combination between the given phase-space points `x` and parameters `theta`. That is, if given 100 events `x` and a grid of 25 `theta` points, it will return 25\\*100 estimates for the log likelihood and 25\\*100 estimates for the  score, both indexed by `[i_theta,i_x]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_each = np.linspace(-100.,100.,11)\n",
    "theta0, theta1 = np.meshgrid(theta_each, theta_each)\n",
    "theta_grid = np.vstack((theta0.flatten(), theta1.flatten())).T\n",
    "np.save('data/theta_grid.npy', theta_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:34  Loading settings from models/rascal_settings.json\n",
      "21:34  Loading state dictionary from models/rascal_state_dict.pt\n",
      "21:34  Starting evaluation\n",
      "21:34  Loading training data\n",
      "21:34  Starting evaluation for theta 1 / 121, [-100. -100.]\n",
      "21:34  Starting evaluation for theta 2 / 121, [ -80. -100.]\n",
      "21:34  Starting evaluation for theta 3 / 121, [ -60. -100.]\n",
      "21:34  Starting evaluation for theta 4 / 121, [ -40. -100.]\n",
      "21:34  Starting evaluation for theta 5 / 121, [ -20. -100.]\n",
      "21:34  Starting evaluation for theta 6 / 121, [   0. -100.]\n",
      "21:34  Starting evaluation for theta 7 / 121, [  20. -100.]\n",
      "21:34  Starting evaluation for theta 8 / 121, [  40. -100.]\n",
      "21:34  Starting evaluation for theta 9 / 121, [  60. -100.]\n",
      "21:34  Starting evaluation for theta 10 / 121, [  80. -100.]\n",
      "21:34  Starting evaluation for theta 11 / 121, [ 100. -100.]\n",
      "21:34  Starting evaluation for theta 12 / 121, [-100.  -80.]\n",
      "21:34  Starting evaluation for theta 13 / 121, [-80. -80.]\n",
      "21:34  Starting evaluation for theta 14 / 121, [-60. -80.]\n",
      "21:34  Starting evaluation for theta 15 / 121, [-40. -80.]\n",
      "21:34  Starting evaluation for theta 16 / 121, [-20. -80.]\n",
      "21:34  Starting evaluation for theta 17 / 121, [  0. -80.]\n",
      "21:34  Starting evaluation for theta 18 / 121, [ 20. -80.]\n",
      "21:34  Starting evaluation for theta 19 / 121, [ 40. -80.]\n",
      "21:34  Starting evaluation for theta 20 / 121, [ 60. -80.]\n",
      "21:34  Starting evaluation for theta 21 / 121, [ 80. -80.]\n",
      "21:34  Starting evaluation for theta 22 / 121, [100. -80.]\n",
      "21:34  Starting evaluation for theta 23 / 121, [-100.  -60.]\n",
      "21:34  Starting evaluation for theta 24 / 121, [-80. -60.]\n",
      "21:34  Starting evaluation for theta 25 / 121, [-60. -60.]\n",
      "21:34  Starting evaluation for theta 26 / 121, [-40. -60.]\n",
      "21:34  Starting evaluation for theta 27 / 121, [-20. -60.]\n",
      "21:34  Starting evaluation for theta 28 / 121, [  0. -60.]\n",
      "21:34  Starting evaluation for theta 29 / 121, [ 20. -60.]\n",
      "21:34  Starting evaluation for theta 30 / 121, [ 40. -60.]\n",
      "21:34  Starting evaluation for theta 31 / 121, [ 60. -60.]\n",
      "21:34  Starting evaluation for theta 32 / 121, [ 80. -60.]\n",
      "21:34  Starting evaluation for theta 33 / 121, [100. -60.]\n",
      "21:34  Starting evaluation for theta 34 / 121, [-100.  -40.]\n",
      "21:34  Starting evaluation for theta 35 / 121, [-80. -40.]\n",
      "21:34  Starting evaluation for theta 36 / 121, [-60. -40.]\n",
      "21:34  Starting evaluation for theta 37 / 121, [-40. -40.]\n",
      "21:34  Starting evaluation for theta 38 / 121, [-20. -40.]\n",
      "21:34  Starting evaluation for theta 39 / 121, [  0. -40.]\n",
      "21:34  Starting evaluation for theta 40 / 121, [ 20. -40.]\n",
      "21:34  Starting evaluation for theta 41 / 121, [ 40. -40.]\n",
      "21:34  Starting evaluation for theta 42 / 121, [ 60. -40.]\n",
      "21:34  Starting evaluation for theta 43 / 121, [ 80. -40.]\n",
      "21:34  Starting evaluation for theta 44 / 121, [100. -40.]\n",
      "21:34  Starting evaluation for theta 45 / 121, [-100.  -20.]\n",
      "21:34  Starting evaluation for theta 46 / 121, [-80. -20.]\n",
      "21:34  Starting evaluation for theta 47 / 121, [-60. -20.]\n",
      "21:34  Starting evaluation for theta 48 / 121, [-40. -20.]\n",
      "21:34  Starting evaluation for theta 49 / 121, [-20. -20.]\n",
      "21:34  Starting evaluation for theta 50 / 121, [  0. -20.]\n",
      "21:34  Starting evaluation for theta 51 / 121, [ 20. -20.]\n",
      "21:34  Starting evaluation for theta 52 / 121, [ 40. -20.]\n",
      "21:34  Starting evaluation for theta 53 / 121, [ 60. -20.]\n",
      "21:34  Starting evaluation for theta 54 / 121, [ 80. -20.]\n",
      "21:34  Starting evaluation for theta 55 / 121, [100. -20.]\n",
      "21:34  Starting evaluation for theta 56 / 121, [-100.    0.]\n",
      "21:34  Starting evaluation for theta 57 / 121, [-80.   0.]\n",
      "21:34  Starting evaluation for theta 58 / 121, [-60.   0.]\n",
      "21:34  Starting evaluation for theta 59 / 121, [-40.   0.]\n",
      "21:34  Starting evaluation for theta 60 / 121, [-20.   0.]\n",
      "21:34  Starting evaluation for theta 61 / 121, [0. 0.]\n",
      "21:34  Starting evaluation for theta 62 / 121, [20.  0.]\n",
      "21:34  Starting evaluation for theta 63 / 121, [40.  0.]\n",
      "21:34  Starting evaluation for theta 64 / 121, [60.  0.]\n",
      "21:34  Starting evaluation for theta 65 / 121, [80.  0.]\n",
      "21:34  Starting evaluation for theta 66 / 121, [100.   0.]\n",
      "21:34  Starting evaluation for theta 67 / 121, [-100.   20.]\n",
      "21:34  Starting evaluation for theta 68 / 121, [-80.  20.]\n",
      "21:34  Starting evaluation for theta 69 / 121, [-60.  20.]\n",
      "21:34  Starting evaluation for theta 70 / 121, [-40.  20.]\n",
      "21:34  Starting evaluation for theta 71 / 121, [-20.  20.]\n",
      "21:34  Starting evaluation for theta 72 / 121, [ 0. 20.]\n",
      "21:34  Starting evaluation for theta 73 / 121, [20. 20.]\n",
      "21:34  Starting evaluation for theta 74 / 121, [40. 20.]\n",
      "21:34  Starting evaluation for theta 75 / 121, [60. 20.]\n",
      "21:34  Starting evaluation for theta 76 / 121, [80. 20.]\n",
      "21:34  Starting evaluation for theta 77 / 121, [100.  20.]\n",
      "21:34  Starting evaluation for theta 78 / 121, [-100.   40.]\n",
      "21:34  Starting evaluation for theta 79 / 121, [-80.  40.]\n",
      "21:34  Starting evaluation for theta 80 / 121, [-60.  40.]\n",
      "21:34  Starting evaluation for theta 81 / 121, [-40.  40.]\n",
      "21:34  Starting evaluation for theta 82 / 121, [-20.  40.]\n",
      "21:34  Starting evaluation for theta 83 / 121, [ 0. 40.]\n",
      "21:34  Starting evaluation for theta 84 / 121, [20. 40.]\n",
      "21:34  Starting evaluation for theta 85 / 121, [40. 40.]\n",
      "21:34  Starting evaluation for theta 86 / 121, [60. 40.]\n",
      "21:34  Starting evaluation for theta 87 / 121, [80. 40.]\n",
      "21:34  Starting evaluation for theta 88 / 121, [100.  40.]\n",
      "21:34  Starting evaluation for theta 89 / 121, [-100.   60.]\n",
      "21:34  Starting evaluation for theta 90 / 121, [-80.  60.]\n",
      "21:34  Starting evaluation for theta 91 / 121, [-60.  60.]\n",
      "21:34  Starting evaluation for theta 92 / 121, [-40.  60.]\n",
      "21:34  Starting evaluation for theta 93 / 121, [-20.  60.]\n",
      "21:34  Starting evaluation for theta 94 / 121, [ 0. 60.]\n",
      "21:34  Starting evaluation for theta 95 / 121, [20. 60.]\n",
      "21:34  Starting evaluation for theta 96 / 121, [40. 60.]\n",
      "21:34  Starting evaluation for theta 97 / 121, [60. 60.]\n",
      "21:34  Starting evaluation for theta 98 / 121, [80. 60.]\n",
      "21:34  Starting evaluation for theta 99 / 121, [100.  60.]\n",
      "21:34  Starting evaluation for theta 100 / 121, [-100.   80.]\n",
      "21:34  Starting evaluation for theta 101 / 121, [-80.  80.]\n",
      "21:34  Starting evaluation for theta 102 / 121, [-60.  80.]\n",
      "21:34  Starting evaluation for theta 103 / 121, [-40.  80.]\n",
      "21:34  Starting evaluation for theta 104 / 121, [-20.  80.]\n",
      "21:34  Starting evaluation for theta 105 / 121, [ 0. 80.]\n",
      "21:34  Starting evaluation for theta 106 / 121, [20. 80.]\n",
      "21:34  Starting evaluation for theta 107 / 121, [40. 80.]\n",
      "21:34  Starting evaluation for theta 108 / 121, [60. 80.]\n",
      "21:34  Starting evaluation for theta 109 / 121, [80. 80.]\n",
      "21:34  Starting evaluation for theta 110 / 121, [100.  80.]\n",
      "21:34  Starting evaluation for theta 111 / 121, [-100.  100.]\n",
      "21:34  Starting evaluation for theta 112 / 121, [-80. 100.]\n",
      "21:34  Starting evaluation for theta 113 / 121, [-60. 100.]\n",
      "21:34  Starting evaluation for theta 114 / 121, [-40. 100.]\n",
      "21:34  Starting evaluation for theta 115 / 121, [-20. 100.]\n",
      "21:34  Starting evaluation for theta 116 / 121, [  0. 100.]\n",
      "21:34  Starting evaluation for theta 117 / 121, [ 20. 100.]\n",
      "21:34  Starting evaluation for theta 118 / 121, [ 40. 100.]\n",
      "21:34  Starting evaluation for theta 119 / 121, [ 60. 100.]\n",
      "21:34  Starting evaluation for theta 120 / 121, [ 80. 100.]\n",
      "21:34  Starting evaluation for theta 121 / 121, [100. 100.]\n"
     ]
    }
   ],
   "source": [
    "forge.load('models/rascal')\n",
    "\n",
    "log_r_hat, t_hat = forge.evaluate(\n",
    "    theta_filename='data/theta_grid.npy',\n",
    "    x_filename='data/samples/x_test.npy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111be8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expected_llr = np.mean(log_r_hat, axis=1)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.scatter(theta_grid[:,0], theta_grid[:,1], c=expected_llr,\n",
    "            s=150., cmap='viridis',\n",
    "            marker='s')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
