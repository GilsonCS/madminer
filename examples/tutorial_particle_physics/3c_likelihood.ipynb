{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MadMiner particle physics tutorial\n",
    "\n",
    "# Part 3c: Training a likelihood estimator\n",
    "\n",
    "Johann Brehmer, Felix Kling, Irina Espejo, and Kyle Cranmer 2018-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 3c of this tutorial we will train a third neural estimator: this time of the likelihood function itself (rather than its ratio). We assume that you have run part 1 and 2a of this tutorial. If, instead of 2a, you have run part 2b, you just have to load a different filename later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer import sampling\n",
    "from madminer.ml import LikelihoodEstimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MadMiner output\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)-5.5s %(name)-20.20s %(levelname)-7.7s %(message)s',\n",
    "    datefmt='%H:%M',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "# Output of all other modules (e.g. matplotlib)\n",
    "for key in logging.Logger.manager.loggerDict:\n",
    "    if \"madminer\" not in key:\n",
    "        logging.getLogger(key).setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make (unweighted) training and test samples with augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have all the information we need from the simulations. But the data is not quite ready to be used for machine learning. The `madminer.sampling` class `SampleAugmenter` will take care of the remaining book-keeping steps before we can train our estimators:\n",
    "\n",
    "First, it unweights the samples, i.e. for a given parameter vector `theta` (or a distribution `p(theta)`) it picks events `x` such that their distribution follows `p(x|theta)`. The selected samples will all come from the event file we have so far, but their frequency is changed -- some events will appear multiple times, some will disappear.\n",
    "\n",
    "Second, `SampleAugmenter` calculates all the augmented data (\"gold\") that is the key to our new inference methods. Depending on the specific technique, these are the joint likelihood ratio and / or the joint score. It saves all these pieces of information for the selected events in a set of numpy files that can easily be used in any machine learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:25 madminer.analysis    INFO    Loading data from data/lhe_data_shuffled.h5\n",
      "14:25 madminer.analysis    INFO    Found 2 parameters\n",
      "14:25 madminer.analysis    INFO    Did not find nuisance parameters\n",
      "14:25 madminer.analysis    INFO    Found 6 benchmarks, of which 6 physical\n",
      "14:25 madminer.analysis    INFO    Found 3 observables\n",
      "14:25 madminer.analysis    INFO    Found 15030 events\n",
      "14:25 madminer.analysis    INFO      10041 generated from sm\n",
      "14:25 madminer.analysis    INFO      1023 generated from w\n",
      "14:25 madminer.analysis    INFO      1127 generated from neg_w\n",
      "14:25 madminer.analysis    INFO      1450 generated from ww\n",
      "14:25 madminer.analysis    INFO      1389 generated from neg_ww\n",
      "14:25 madminer.analysis    INFO    Found morphing setup with 6 components\n",
      "14:25 madminer.analysis    INFO    Did not find nuisance morphing setup\n"
     ]
    }
   ],
   "source": [
    "sampler = SampleAugmenter('data/lhe_data_shuffled.h5')\n",
    "# sampler = SampleAugmenter('data/delphes_data_shuffled.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SampleAugmenter` class defines five different high-level functions to generate train or test samples:\n",
    "- `sample_train_plain()`, which only saves observations x, for instance for histograms or ABC;\n",
    "- `sample_train_local()` for methods like SALLY and SALLINO, which will be demonstrated in the second part of the tutorial;\n",
    "- `sample_train_density()` for neural density estimation techniques like MAF or SCANDAL;\n",
    "- `sample_train_ratio()` for techniques like CARL, ROLR, CASCAL, and RASCAL, when only theta0 is parameterized;\n",
    "- `sample_train_more_ratios()` for the same techniques, but with both theta0 and theta1 parameterized;\n",
    "- `sample_test()` for the evaluation of any method.\n",
    "\n",
    "For the arguments `theta`, `theta0`, or `theta1`, you can (and should!) use the helper functions `benchmark()`, `benchmarks()`, `morphing_point()`, `morphing_points()`, and `random_morphing_points()`, all defined in the `madminer.sampling` module.\n",
    "\n",
    "Here we'll train a likelihood estimator with the SCANDAL method, so we focus on the `extract_samples_train_density()` function. We'll sample the numerator hypothesis in the likelihood ratio with 1000 points drawn from a Gaussian prior, and fix the denominator hypothesis to the SM.\n",
    "\n",
    "Note the keyword `sample_only_from_closest_benchmark=True`, which makes sure that for each parameter point we only use the events that were originally (in MG) generated from the closest benchmark. This reduces the statistical fluctuations in the outcome quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.sample_train_density?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:28 madminer.sampling    INFO    Extracting training sample for non-local score-based methods. Sampling and score evaluation according to ('random_morphing_points', (1000, [('gaussian', 0.0, 15.0), ('gaussian', 0.0, 15.0)]))\n",
      "14:28 madminer.sampling    INFO    Starting sampling serially\n",
      "14:28 madminer.sampling    WARNING Large statistical uncertainty on the total cross section when sampling from theta = [ 10.46578532 -13.48456144]: (0.007204 +/- 0.000782) pb (10.856935261838029 %). Skipping these warnings in the future...\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 50 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 100 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 150 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 200 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 250 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 300 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 350 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 400 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 450 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 500 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 550 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 600 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 650 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 700 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 750 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 800 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 850 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 900 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 950 / 1000\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 1000 / 1000\n",
      "14:28 madminer.sampling    INFO    Effective number of samples: mean 152.23627255896426, with individual thetas ranging from 9.92312814723694 to 1969.5665616648787\n"
     ]
    }
   ],
   "source": [
    "x, theta, t_xz, _ = sampler.sample_train_density(\n",
    "    theta=sampling.random_morphing_points(1000, [('gaussian', 0., 15.), ('gaussian', 0., 15.)]),\n",
    "    n_samples=100000,\n",
    "    folder='./data/samples',\n",
    "    filename='train_density',\n",
    "    sample_only_from_closest_benchmark=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evaluation we'll need a test sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:28 madminer.sampling    INFO    Extracting evaluation sample. Sampling according to sm\n",
      "14:28 madminer.sampling    INFO    Starting sampling serially\n",
      "14:28 madminer.sampling    INFO    Sampling from parameter point 1 / 1\n",
      "14:28 madminer.sampling    INFO    Effective number of samples: mean 19.046228721636165, with individual thetas ranging from 19.046228721636165 to 19.046228721636165\n"
     ]
    }
   ],
   "source": [
    "_ = sampler.sample_test(\n",
    "    theta=sampling.benchmark('sm'),\n",
    "    n_samples=1000,\n",
    "    folder='./data/samples',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to build the neural network that estimates the likelihood ratio. The central object for this is the `madminer.ml.ParameterizedRatioEstimator` class. It defines functions that train, save, load, and evaluate the estimators.\n",
    "\n",
    "In the initialization, the keywords `n_hidden` and `activation` define the architecture of the (fully connected) neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LikelihoodEstimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LikelihoodEstimator(\n",
    "    n_mades=3,\n",
    "    n_hidden=(100,),\n",
    "    activation=\"tanh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train this model we will minimize the SCANDAL loss function described in [\"Mining gold from implicit models to improve likelihood-free inference\"](https://arxiv.org/abs/1805.12244)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:29 madminer.ml          INFO    Starting training\n",
      "14:29 madminer.ml          INFO      Method:                 scandal\n",
      "14:29 madminer.ml          INFO      alpha:                  1.0\n",
      "14:29 madminer.ml          INFO      Batch size:             200\n",
      "14:29 madminer.ml          INFO      Optimizer:              amsgrad\n",
      "14:29 madminer.ml          INFO      Epochs:                 20\n",
      "14:29 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "14:29 madminer.ml          INFO      Validation split:       0.25\n",
      "14:29 madminer.ml          INFO      Early stopping:         True\n",
      "14:29 madminer.ml          INFO      Scale inputs:           True\n",
      "14:29 madminer.ml          INFO      Shuffle labels          False\n",
      "14:29 madminer.ml          INFO      Samples:                all\n",
      "14:29 madminer.ml          INFO    Loading training data\n",
      "14:29 madminer.ml          INFO    Found 100000 samples with 2 parameters and 3 observables\n",
      "14:29 madminer.ml          INFO    Rescaling inputs\n",
      "14:29 madminer.ml          INFO    Training model\n",
      "14:29 madminer.utils.ml.tr INFO    Training on CPU with single precision\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   1: train loss  3.84433 (nll:  3.807, mse_score:  0.037)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.63021 (nll:  3.605, mse_score:  0.025)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   2: train loss  3.60081 (nll:  3.578, mse_score:  0.023)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.59023 (nll:  3.569, mse_score:  0.021)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   3: train loss  3.57843 (nll:  3.558, mse_score:  0.020)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.58978 (nll:  3.570, mse_score:  0.020)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   4: train loss  3.56922 (nll:  3.551, mse_score:  0.019)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.57411 (nll:  3.556, mse_score:  0.018)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   5: train loss  3.56148 (nll:  3.544, mse_score:  0.018)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.56463 (nll:  3.547, mse_score:  0.017)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   6: train loss  3.55831 (nll:  3.541, mse_score:  0.017)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.56257 (nll:  3.545, mse_score:  0.017)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   7: train loss  3.55121 (nll:  3.534, mse_score:  0.017)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.56328 (nll:  3.546, mse_score:  0.017)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   8: train loss  3.54830 (nll:  3.532, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.55336 (nll:  3.537, mse_score:  0.017)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch   9: train loss  3.54489 (nll:  3.529, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.55026 (nll:  3.534, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch  10: train loss  3.54250 (nll:  3.527, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.55399 (nll:  3.538, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch  11: train loss  3.54088 (nll:  3.525, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.54829 (nll:  3.532, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch  12: train loss  3.53792 (nll:  3.522, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.55055 (nll:  3.534, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch  13: train loss  3.53628 (nll:  3.521, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.54735 (nll:  3.532, mse_score:  0.016)\n",
      "14:30 madminer.utils.ml.tr INFO    Epoch  14: train loss  3.53570 (nll:  3.520, mse_score:  0.015)\n",
      "14:30 madminer.utils.ml.tr INFO               val. loss   3.54733 (nll:  3.532, mse_score:  0.016)\n",
      "14:31 madminer.utils.ml.tr INFO    Epoch  15: train loss  3.53372 (nll:  3.518, mse_score:  0.015)\n",
      "14:31 madminer.utils.ml.tr INFO               val. loss   3.54453 (nll:  3.529, mse_score:  0.016)\n",
      "14:31 madminer.utils.ml.tr INFO    Epoch  16: train loss  3.53251 (nll:  3.517, mse_score:  0.015)\n",
      "14:31 madminer.utils.ml.tr INFO               val. loss   3.54505 (nll:  3.529, mse_score:  0.016)\n",
      "14:31 madminer.utils.ml.tr INFO    Epoch  17: train loss  3.53159 (nll:  3.516, mse_score:  0.015)\n",
      "14:31 madminer.utils.ml.tr INFO               val. loss   3.54394 (nll:  3.528, mse_score:  0.016)\n",
      "14:31 madminer.utils.ml.tr INFO    Epoch  18: train loss  3.53083 (nll:  3.516, mse_score:  0.015)\n",
      "14:31 madminer.utils.ml.tr INFO               val. loss   3.54209 (nll:  3.526, mse_score:  0.016)\n",
      "14:31 madminer.utils.ml.tr INFO    Epoch  19: train loss  3.53006 (nll:  3.515, mse_score:  0.015)\n",
      "14:31 madminer.utils.ml.tr INFO               val. loss   3.54228 (nll:  3.527, mse_score:  0.016)\n",
      "14:31 madminer.utils.ml.tr INFO    Epoch  20: train loss  3.52926 (nll:  3.514, mse_score:  0.015)\n",
      "14:31 madminer.utils.ml.tr INFO               val. loss   3.54328 (nll:  3.528, mse_score:  0.016)\n",
      "14:31 madminer.utils.ml.tr INFO    Early stopping after epoch 18, with loss  3.54209 compared to final loss  3.54328\n",
      "14:31 root                 INFO    Training time spend on:\n",
      "14:31 root                 INFO                      initialize model:   0.00h\n",
      "14:31 root                 INFO                                   ALL:   0.02h\n",
      "14:31 root                 INFO                            check data:   0.00h\n",
      "14:31 root                 INFO                          make dataset:   0.00h\n",
      "14:31 root                 INFO                       make dataloader:   0.00h\n",
      "14:31 root                 INFO                       setup optimizer:   0.00h\n",
      "14:31 root                 INFO                   initialize training:   0.00h\n",
      "14:31 root                 INFO                                set lr:   0.00h\n",
      "14:31 root                 INFO                   load training batch:   0.00h\n",
      "14:31 root                 INFO                        fwd: move data:   0.00h\n",
      "14:31 root                 INFO                   fwd: check for nans:   0.00h\n",
      "14:31 root                 INFO                    fwd: model.forward:   0.01h\n",
      "14:31 root                 INFO                 fwd: calculate losses:   0.00h\n",
      "14:31 root                 INFO                 training forward pass:   0.01h\n",
      "14:31 root                 INFO                   training sum losses:   0.00h\n",
      "14:31 root                 INFO                        opt: zero grad:   0.00h\n",
      "14:31 root                 INFO                         opt: backward:   0.01h\n",
      "14:31 root                 INFO                   opt: clip grad norm:   0.00h\n",
      "14:31 root                 INFO                             opt: step:   0.00h\n",
      "14:31 root                 INFO                        optimizer step:   0.01h\n",
      "14:31 root                 INFO                 load validation batch:   0.00h\n",
      "14:31 root                 INFO               validation forward pass:   0.00h\n",
      "14:31 root                 INFO                 validation sum losses:   0.00h\n",
      "14:31 root                 INFO                        early stopping:   0.00h\n",
      "14:31 root                 INFO                          report epoch:   0.00h\n"
     ]
    }
   ],
   "source": [
    "estimator.train(\n",
    "    method='scandal',\n",
    "    theta='data/samples/theta_train_density.npy',\n",
    "    x='data/samples/x_train_density.npy',\n",
    "    t_xz='data/samples/t_xz_train_density.npy',\n",
    "    alpha=1.,\n",
    "    n_epochs=20,\n",
    ")\n",
    "\n",
    "estimator.save('models/scandal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate likelihood estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`estimator.evaluate_log_likelihood(theta,x)` estimated the log likelihood for all combination between the given phase-space points `x` and parameters `theta`. That is, if given 100 events `x` and a grid of 25 `theta` points, it will return 25\\*100 estimates for the log likelihood, indexed by `[i_theta,i_x]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_each = np.linspace(-20.,20.,21)\n",
    "theta0, theta1 = np.meshgrid(theta_each, theta_each)\n",
    "theta_grid = np.vstack((theta0.flatten(), theta1.flatten())).T\n",
    "np.save('data/samples/theta_grid.npy', theta_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.load('models/scandal')\n",
    "\n",
    "log_p_hat, _ = estimator.evaluate_log_likelihood(\n",
    "    theta='data/samples/theta_grid.npy',\n",
    "    x='data/samples/x_test.npy',\n",
    "    evaluate_score=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_size = theta_each[1] - theta_each[0]\n",
    "edges = np.linspace(theta_each[0] - bin_size/2, theta_each[-1] + bin_size/2, len(theta_each)+1)\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = plt.gca()\n",
    "\n",
    "expected_llr = np.mean(log_p_hat,axis=1)\n",
    "best_fit = theta_grid[np.argmin(-2.*expected_llr)]\n",
    "\n",
    "cmin, cmax = np.min(-2*expected_llr), np.max(-2*expected_llr)\n",
    "    \n",
    "pcm = ax.pcolormesh(edges, edges, -2. * expected_llr.reshape((21,21)),\n",
    "                    norm=matplotlib.colors.Normalize(vmin=cmin, vmax=cmax),\n",
    "                    cmap='viridis_r')\n",
    "cbar = fig.colorbar(pcm, ax=ax, extend='both')\n",
    "\n",
    "plt.scatter(best_fit[0], best_fit[1], s=80., color='black', marker='*')\n",
    "\n",
    "plt.xlabel(r'$\\theta_0$')\n",
    "plt.ylabel(r'$\\theta_1$')\n",
    "cbar.set_label(r'$\\mathbb{E}_x [ -2\\, \\log \\,\\hat{r}(x | \\theta, \\theta_{SM}) ]$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this tutorial our sample size was very small, and the network might not really have a chance to converge to the correct likelihood function. So don't worry if you find a minimum that is not at the right point (the SM, i.e. the origin in this plot). Feel free to dial up the event numbers in the run card as well as the training samples and see what happens then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (higgs_inference)",
   "language": "python",
   "name": "higgs_inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
